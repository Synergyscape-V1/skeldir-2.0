# B0544_EVIDENCE_PACK_local_windows.md

## Repo Identity

- sha: 65dc2115b2ff5f33f4258e72dcf1b214ebfcebbb
- timestamp_utc: 2026-01-04T03:10:36.1863377Z
- env note: DATABASE_URL set to postgresql://app_user:app_user@localhost:5432/skeldir_validation for beat_schedule dump

## Hypothesis Validation Evidence

### H-B0544-1 (Topology: beat entrypoint)

Command:

```
rg -n "celery .*beat|celerybeat|--beat|beat -S|Scheduler" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
```

Output:

```
.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_schedule_defs.txt:6:.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:7:.\B0544_CONTEXT_DUMP.md:57:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:9:.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:10:.\B0544_CONTEXT_DUMP.md:60:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:16:.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:17:.\B0544_CONTEXT_DUMP.md:67:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:19:.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:20:.\B0544_CONTEXT_DUMP.md:70:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:24:.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:25:.\B0544_CONTEXT_DUMP.md:75:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:27:.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:28:.\B0544_CONTEXT_DUMP.md:78:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:47:.\B0544_CONTEXT_DUMP.md:97:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_tmp\grep_schedule_defs.txt:63:.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:64:.\B0544_CONTEXT_DUMP.md:334:.\B0544_tmp\cmd1.txt:3:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:65:.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:66:.\B0544_CONTEXT_DUMP.md:336:.\B0544_tmp\cmd1.txt:6:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:67:.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:68:.\B0544_CONTEXT_DUMP.md:338:.\B0544_tmp\cmd1.txt:13:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:69:.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:70:.\B0544_CONTEXT_DUMP.md:340:.\B0544_tmp\cmd1.txt:16:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:71:.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:72:.\B0544_CONTEXT_DUMP.md:342:.\B0544_tmp\cmd1.txt:21:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:73:.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:74:.\B0544_CONTEXT_DUMP.md:344:.\B0544_tmp\cmd1.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:75:.\B0544_CONTEXT_DUMP.md:345:.\B0544_tmp\cmd1.txt:43:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_tmp\grep_schedule_defs.txt:76:.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:77:.\B0544_CONTEXT_DUMP.md:347:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:78:.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:79:.\B0544_CONTEXT_DUMP.md:349:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:80:.\B0544_CONTEXT_DUMP.md:350:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_tmp\grep_schedule_defs.txt:81:.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:82:.\B0544_CONTEXT_DUMP.md:352:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:83:.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:84:.\B0544_CONTEXT_DUMP.md:354:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:85:.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:86:.\B0544_CONTEXT_DUMP.md:357:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:87:.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:88:.\B0544_CONTEXT_DUMP.md:368:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:92:.\B0544_CONTEXT_DUMP.md:412:scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_schedule_defs.txt:122:.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:123:.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:124:.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:125:.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:126:.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:127:.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:128:.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:129:.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:130:.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:131:.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:132:.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:133:.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:134:.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:135:.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:136:.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:137:.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:138:.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:139:.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:140:.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:141:.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:142:.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:143:.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:144:.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:145:.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:146:.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\B0544_tmp\grep_schedule_defs.txt:148:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:149:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:151:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:152:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:154:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:155:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:157:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:158:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:160:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:161:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:163:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:164:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_tmp\grep_schedule_defs.txt:189:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:57:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:60:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:67:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:70:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:75:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:78:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:97:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:327:rg -n "celery .*beat|celerybeat|--beat|beat -S|Scheduler" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:334:.\B0544_tmp\cmd1.txt:3:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:336:.\B0544_tmp\cmd1.txt:6:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:338:.\B0544_tmp\cmd1.txt:13:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:340:.\B0544_tmp\cmd1.txt:16:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:342:.\B0544_tmp\cmd1.txt:21:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:344:.\B0544_tmp\cmd1.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:345:.\B0544_tmp\cmd1.txt:43:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:347:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:349:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:350:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:352:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:354:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:355:.\docs\evidence\b0540_ci_truthlayer_evidence.md:33:- **Beat dispatch proof (ZG-5)**: `Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.maintenance.refresh_all_matviews_global_legacy)` repeats with 1s interval (`tmp/zero_drift_v3_2_run7.log` lines @ `2025-12-21T18:40:04Z`???`18:40:22Z`), demonstrating dispatch, not just startup.
.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:357:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:358:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:152:[2025-12-20 12:51:21,656: INFO/MainProcess] Scheduler: Sending due task pii-audit-scanner (app.tasks.maintenance.scan_for_pii_contamination)
.\B0544_CONTEXT_DUMP.md:359:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:153:[2025-12-20 12:51:21,748: INFO/MainProcess] Scheduler: Sending due task enforce-data-retention (app.tasks.maintenance.enforce_data_retention)
.\B0544_CONTEXT_DUMP.md:360:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:154:[2025-12-20 12:51:21,752: INFO/MainProcess] Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.maintenance.refresh_all_matviews_global_legacy)
.\B0544_CONTEXT_DUMP.md:361:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:654:**Selected Mechanism**: Celery Beat (Application-Layer Scheduler)
.\B0544_CONTEXT_DUMP.md:362:.\docs\evidence\b054-forensic-readiness-evidence.md:47:# Standard command would be: celery -A app.celery_app.celery_app beat --loglevel=INFO
.\B0544_CONTEXT_DUMP.md:363:.\docs\evidence\b054-forensic-readiness-evidence.md:641:   - **No `celery beat` process**
.\B0544_CONTEXT_DUMP.md:364:.\docs\evidence\b054-forensic-readiness-evidence.md:658:- CI does NOT start `celery beat` process
.\B0544_CONTEXT_DUMP.md:365:.\docs\evidence\b054-forensic-readiness-evidence.md:818:- CI does NOT start `celery beat` process
.\B0544_CONTEXT_DUMP.md:366:.\docs\evidence\b054-forensic-readiness-evidence.md:994:3. **Deploy Beat:** Add `celery beat` startup command to CI and local docs
.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:368:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:412:scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:499:### 6) Competing scheduler search (cron/APScheduler/loop)
.\B0544_CONTEXT_DUMP.md:504:rg -n "cron|crontab|APScheduler|schedule\.every|while True|sleep\(|timer|Periodic|background job" -S --glob "!**/.git/**" --glob "!**/node_modules/**" backend scripts .
.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:654:**Selected Mechanism**: Celery Beat (Application-Layer Scheduler)
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\docs\evidence\b0540_ci_truthlayer_evidence.md:33:- **Beat dispatch proof (ZG-5)**: `Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.maintenance.refresh_all_matviews_global_legacy)` repeats with 1s interval (`tmp/zero_drift_v3_2_run7.log` lines @ `2025-12-21T18:40:04Z`???`18:40:22Z`), demonstrating dispatch, not just startup.
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:152:[2025-12-20 12:51:21,656: INFO/MainProcess] Scheduler: Sending due task pii-audit-scanner (app.tasks.maintenance.scan_for_pii_contamination)
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:153:[2025-12-20 12:51:21,748: INFO/MainProcess] Scheduler: Sending due task enforce-data-retention (app.tasks.maintenance.enforce_data_retention)
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:154:[2025-12-20 12:51:21,752: INFO/MainProcess] Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.maintenance.refresh_all_matviews_global_legacy)
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\evidence\b054-forensic-readiness-evidence.md:47:# Standard command would be: celery -A app.celery_app.celery_app beat --loglevel=INFO
.\docs\evidence\b054-forensic-readiness-evidence.md:641:   - **No `celery beat` process**
.\docs\evidence\b054-forensic-readiness-evidence.md:658:- CI does NOT start `celery beat` process
.\docs\evidence\b054-forensic-readiness-evidence.md:818:- CI does NOT start `celery beat` process
.\docs\evidence\b054-forensic-readiness-evidence.md:994:3. **Deploy Beat:** Add `celery beat` startup command to CI and local docs
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
```

### H-B0544-2 (Signature: no-arg global adapter)

Command:

```
rg -n "refresh_all_for_tenant" -S backend/app
```

Output:

```
backend/app\matviews\executor.py:184:async def refresh_all_for_tenant_async(
backend/app\matviews\executor.py:195:def refresh_all_for_tenant(
backend/app\matviews\executor.py:205:        return asyncio.run(refresh_all_for_tenant_async(tenant_id, correlation_id))
backend/app\matviews\executor.py:206:    raise RuntimeError("refresh_all_for_tenant cannot run inside an active event loop")
backend/app\tasks\matviews.py:15:from app.matviews.executor import RefreshOutcome, RefreshResult, refresh_all_for_tenant, refresh_single
backend/app\tasks\matviews.py:174:    name="app.tasks.matviews.refresh_all_for_tenant",
backend/app\tasks\matviews.py:180:def matview_refresh_all_for_tenant(
backend/app\tasks\matviews.py:197:    results = refresh_all_for_tenant(tenant_id, correlation_id)

### H-B0544-3 / H-B0544-4 (Schedule keys + governance entries)

Command:

```
$env:DATABASE_URL='postgresql://app_user:app_user@localhost:5432/skeldir_validation'; python -c "import sys; sys.path.append('backend'); from app.celery_app import celery_app; print(celery_app.conf.beat_schedule); print(list((celery_app.conf.beat_schedule or {}).keys()))"
```

Output:

```
{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}
['refresh-matviews-every-5-min', 'pii-audit-scanner', 'enforce-data-retention']
```

### H-B0544-5 (R6 governance fuses)

Command:

```
rg -n "task_time_limit|task_soft_time_limit|max_tasks_per_child|prefetch|acks_late|reject_on_worker_lost|task_routes|task_default_queue" -S backend/app
```

Output:

```
backend/app\celery_app.py:147:        task_acks_late=settings.CELERY_TASK_ACKS_LATE,
backend/app\celery_app.py:148:        task_reject_on_worker_lost=settings.CELERY_TASK_REJECT_ON_WORKER_LOST,
backend/app\celery_app.py:150:        worker_prefetch_multiplier=settings.CELERY_WORKER_PREFETCH_MULTIPLIER,
backend/app\celery_app.py:151:        task_soft_time_limit=settings.CELERY_TASK_SOFT_TIME_LIMIT_S,
backend/app\celery_app.py:152:        task_time_limit=settings.CELERY_TASK_TIME_LIMIT_S,
backend/app\celery_app.py:153:        worker_max_tasks_per_child=settings.CELERY_WORKER_MAX_TASKS_PER_CHILD,
backend/app\celery_app.py:180:        task_routes={
backend/app\celery_app.py:189:        task_default_queue='housekeeping',
backend/app\core\config.py:62:    CELERY_TASK_ACKS_LATE: bool = Field(
backend/app\core\config.py:66:    CELERY_TASK_REJECT_ON_WORKER_LOST: bool = Field(
backend/app\core\config.py:74:    CELERY_WORKER_PREFETCH_MULTIPLIER: int = Field(
backend/app\core\config.py:76:        description="Prefetch multiplier for worker (1 minimizes starvation and improves crash determinism).",
backend/app\core\config.py:78:    CELERY_TASK_SOFT_TIME_LIMIT_S: int = Field(
backend/app\core\config.py:82:    CELERY_TASK_TIME_LIMIT_S: int = Field(
backend/app\core\config.py:86:    CELERY_WORKER_MAX_TASKS_PER_CHILD: int = Field(
backend/app\core\config.py:177:    @field_validator("CELERY_WORKER_PREFETCH_MULTIPLIER")
backend/app\core\config.py:179:    def validate_celery_prefetch_multiplier(cls, value: int) -> int:
backend/app\core\config.py:181:            raise ValueError("CELERY_WORKER_PREFETCH_MULTIPLIER must be >= 1")
backend/app\core\config.py:184:    @field_validator("CELERY_TASK_SOFT_TIME_LIMIT_S", "CELERY_TASK_TIME_LIMIT_S")
backend/app\core\config.py:186:    def validate_celery_task_time_limits(cls, value: int, info) -> int:
backend/app\core\config.py:191:    @field_validator("CELERY_WORKER_MAX_TASKS_PER_CHILD", "CELERY_WORKER_MAX_MEMORY_PER_CHILD_KB")
backend/app\tasks\r4_failure_semantics.py:111:    acks_late=False,
backend/app\tasks\r4_failure_semantics.py:166:    acks_late=True,
backend/app\tasks\r4_failure_semantics.py:255:@celery_app.task(bind=True, name="app.tasks.r4_failure_semantics.rls_cross_tenant_probe", acks_late=False)
backend/app\tasks\r4_failure_semantics.py:299:    acks_late=False,
backend/app\tasks\r4_failure_semantics.py:328:@celery_app.task(bind=True, name="app.tasks.r4_failure_semantics.sentinel_side_effect", acks_late=False)
backend/app\tasks\r4_failure_semantics.py:350:@celery_app.task(bind=True, name="app.tasks.r4_failure_semantics.privilege_probes", acks_late=False)
backend/app\tasks\r6_resource_governance.py:73:    acks_late=False,
backend/app\tasks\r6_resource_governance.py:89:            "task_time_limit": getattr(conf, "task_time_limit", None),
backend/app\tasks\r6_resource_governance.py:90:            "task_soft_time_limit": getattr(conf, "task_soft_time_limit", None),
backend/app\tasks\r6_resource_governance.py:91:            "task_acks_late": bool(getattr(conf, "task_acks_late", False)),
backend/app\tasks\r6_resource_governance.py:92:            "task_reject_on_worker_lost": bool(getattr(conf, "task_reject_on_worker_lost", False)),
backend/app\tasks\r6_resource_governance.py:96:            "worker_prefetch_multiplier": int(
backend/app\tasks\r6_resource_governance.py:97:                getattr(conf, "worker_prefetch_multiplier", 0) or 0
backend/app\tasks\r6_resource_governance.py:99:            "worker_max_tasks_per_child": getattr(conf, "worker_max_tasks_per_child", None),
backend/app\tasks\r6_resource_governance.py:106:        "task_default_queue": getattr(conf, "task_default_queue", None),
backend/app\tasks\r6_resource_governance.py:111:            "CELERYD_PREFETCH_MULTIPLIER": os.getenv("CELERYD_PREFETCH_MULTIPLIER"),
backend/app\tasks\r6_resource_governance.py:112:            "CELERYD_MAX_TASKS_PER_CHILD": os.getenv("CELERYD_MAX_TASKS_PER_CHILD"),
backend/app\tasks\r6_resource_governance.py:193:    name="app.tasks.r6_resource_governance.prefetch_short_task",
backend/app\tasks\r6_resource_governance.py:196:def prefetch_short_task(self, run_id: str, index: int) -> dict:
backend/app\tasks\r6_resource_governance.py:199:        f"r6_prefetch_short_start run_id={run_id} task_id={self.request.id} index={index}",
backend/app\tasks\r6_resource_governance.py:214:        f"r6_prefetch_short_end run_id={run_id} task_id={self.request.id} index={index}",
backend/app\tasks\r6_resource_governance.py:231:    name="app.tasks.r6_resource_governance.prefetch_long_task",
backend/app\tasks\r6_resource_governance.py:234:def prefetch_long_task(self, run_id: str, index: int, sleep_s: float = 2.0) -> dict:
backend/app\tasks\r6_resource_governance.py:237:        f"r6_prefetch_long_start run_id={run_id} task_id={self.request.id} index={index}",
backend/app\tasks\r6_resource_governance.py:252:        f"r6_prefetch_long_end run_id={run_id} task_id={self.request.id} index={index}",
```

## Additional Raw Outputs (Entry points and competing schedulers)

### Schedule definition search

Command:

```
rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
```

Output:

```
.\B0544_CONTEXT_DUMP.md:12:- beat schedule definition: backend/app/tasks/beat_schedule.py
.\B0544_CONTEXT_DUMP.md:22:Reasoning: A beat schedule is defined in backend/app/tasks/beat_schedule.py (build_beat_schedule + BEAT_SCHEDULE) and is loaded in backend/app/celery_app.py via celery_app.conf.beat_schedule = BEAT_SCHEDULE. The grep output shows beat_schedule references in the codebase, including the loader in celery_app.py. This indicates a schedule exists, not just hooks.
.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:55:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:57:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:58:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:60:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:61:.\backend\app\tasks\beat_schedule.py:33:def build_beat_schedule() -> Dict[str, Dict[str, Any]]:
.\B0544_CONTEXT_DUMP.md:62:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:63:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:64:.\backend\app\tasks\beat_schedule.py:55:BEAT_SCHEDULE = build_beat_schedule()
.\B0544_CONTEXT_DUMP.md:65:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:67:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:68:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:70:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:71:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_CONTEXT_DUMP.md:72:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_CONTEXT_DUMP.md:73:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:75:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:76:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:78:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:79:.\backend\app\celery_app.py:195:    from app.tasks.beat_schedule import BEAT_SCHEDULE
.\B0544_CONTEXT_DUMP.md:80:.\backend\app\celery_app.py:196:    celery_app.conf.beat_schedule = BEAT_SCHEDULE
.\B0544_CONTEXT_DUMP.md:81:.\backend\app\celery_app.py:205:            "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
.\B0544_CONTEXT_DUMP.md:82:.\backend\app\celery_app.py:206:            "scheduled_tasks": list(celery_app.conf.beat_schedule.keys()) if celery_app.conf.beat_schedule else [],
.\B0544_CONTEXT_DUMP.md:83:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:129:    'beat_schedule_loaded': bool(celery_app.conf.beat_schedule),
.\B0544_CONTEXT_DUMP.md:84:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:130:    'task_count': len(celery_app.conf.beat_schedule or {}),
.\B0544_CONTEXT_DUMP.md:85:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:133:        for name, entry in (celery_app.conf.beat_schedule or {}).items()
.\B0544_CONTEXT_DUMP.md:86:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:138:  "beat_schedule_loaded": true,
.\B0544_CONTEXT_DUMP.md:87:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:88:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:89:.\docs\evidence\b054-forensic-readiness-evidence.md:634:   - **No `beat_schedule` key in conf.update()**
.\B0544_CONTEXT_DUMP.md:90:.\docs\evidence\b054-forensic-readiness-evidence.md:635:   - **Missing:** `beat_schedule=BEAT_SCHEDULE` assignment
.\B0544_CONTEXT_DUMP.md:91:.\docs\evidence\b054-forensic-readiness-evidence.md:953:- **Required Fix:** Load beat_schedule into celery_app.conf AND start Beat process (or use alternative scheduler)
.\B0544_CONTEXT_DUMP.md:92:.\docs\evidence\b054-forensic-readiness-evidence.md:978:2. **G11 BLOCKER addressed:** Load beat_schedule and deploy Beat process OR use alternative scheduling
.\B0544_CONTEXT_DUMP.md:93:.\docs\evidence\b054-forensic-readiness-evidence.md:993:2. **Fix G11:** Add `celery_app.conf.beat_schedule = BEAT_SCHEDULE` in celery_app.py:154
.\B0544_CONTEXT_DUMP.md:94:.\scripts\ci\zero_drift_v3_2.sh:132:    "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
.\B0544_CONTEXT_DUMP.md:95:.\scripts\ci\zero_drift_v3_2.sh:133:    "task_count": len(celery_app.conf.beat_schedule or {}),
.\B0544_CONTEXT_DUMP.md:96:.\scripts\ci\zero_drift_v3_2.sh:134:    "tasks": {name: {"task": entry["task"], "schedule": str(entry["schedule"])} for name, entry in (celery_app.conf.beat_schedule or {}).items()},
.\B0544_CONTEXT_DUMP.md:97:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:121:backend\app\celery_app.py:195:    from app.tasks.beat_schedule import BEAT_SCHEDULE
.\B0544_CONTEXT_DUMP.md:122:backend\app\celery_app.py:196:    celery_app.conf.beat_schedule = BEAT_SCHEDULE
.\B0544_CONTEXT_DUMP.md:123:backend\app\celery_app.py:205:            "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
.\B0544_CONTEXT_DUMP.md:124:backend\app\celery_app.py:206:            "scheduled_tasks": list(celery_app.conf.beat_schedule.keys()) if celery_app.conf.beat_schedule else [],
.\B0544_CONTEXT_DUMP.md:169:backend\app\tasks\beat_schedule.py:2:Celery Beat schedule definitions.
.\B0544_CONTEXT_DUMP.md:170:backend\app\tasks\beat_schedule.py:6:so beat dispatch evidence appears within short CI timeboxes.
.\B0544_CONTEXT_DUMP.md:171:backend\app\tasks\beat_schedule.py:17:    Return the refresh interval for matview refresh.
.\B0544_CONTEXT_DUMP.md:172:backend\app\tasks\beat_schedule.py:19:    CI can override via ZG_BEAT_TEST_INTERVAL_SECONDS to force fast dispatch
.\B0544_CONTEXT_DUMP.md:173:backend\app\tasks\beat_schedule.py:22:    override = os.getenv("ZG_BEAT_TEST_INTERVAL_SECONDS")
.\B0544_CONTEXT_DUMP.md:174:backend\app\tasks\beat_schedule.py:33:def build_beat_schedule() -> Dict[str, Dict[str, Any]]:
.\B0544_CONTEXT_DUMP.md:175:backend\app\tasks\beat_schedule.py:36:        "refresh-matviews-every-5-min": {
.\B0544_CONTEXT_DUMP.md:176:backend\app\tasks\beat_schedule.py:37:            "task": "app.tasks.maintenance.refresh_all_matviews_global_legacy",
.\B0544_CONTEXT_DUMP.md:177:backend\app\tasks\beat_schedule.py:42:            "task": "app.tasks.maintenance.scan_for_pii_contamination",
.\B0544_CONTEXT_DUMP.md:178:backend\app\tasks\beat_schedule.py:47:            "task": "app.tasks.maintenance.enforce_data_retention",
.\B0544_CONTEXT_DUMP.md:179:backend\app\tasks\beat_schedule.py:55:BEAT_SCHEDULE = build_beat_schedule()
.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:334:.\B0544_tmp\cmd1.txt:3:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:336:.\B0544_tmp\cmd1.txt:6:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:338:.\B0544_tmp\cmd1.txt:13:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:340:.\B0544_tmp\cmd1.txt:16:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:342:.\B0544_tmp\cmd1.txt:21:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:344:.\B0544_tmp\cmd1.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:345:.\B0544_tmp\cmd1.txt:43:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:347:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:349:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:350:.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:352:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:354:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:357:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:368:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\B0544_CONTEXT_DUMP.md:409:scripts\ci\zero_drift_v3_2.sh:132:    "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
.\B0544_CONTEXT_DUMP.md:410:scripts\ci\zero_drift_v3_2.sh:133:    "task_count": len(celery_app.conf.beat_schedule or {}),
.\B0544_CONTEXT_DUMP.md:411:scripts\ci\zero_drift_v3_2.sh:134:    "tasks": {name: {"task": entry["task"], "schedule": str(entry["schedule"])} for name, entry in (celery_app.conf.beat_schedule or {}).items()},
.\B0544_CONTEXT_DUMP.md:412:scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
.\B0544_CONTEXT_DUMP.md:527:.\B0544_tmp\cmd1.txt:1:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:528:.\B0544_tmp\cmd1.txt:4:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:529:.\B0544_tmp\cmd1.txt:8:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:530:.\B0544_tmp\cmd1.txt:9:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:531:.\B0544_tmp\cmd1.txt:11:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:532:.\B0544_tmp\cmd1.txt:14:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:533:.\B0544_tmp\cmd1.txt:17:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_CONTEXT_DUMP.md:534:.\B0544_tmp\cmd1.txt:18:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_CONTEXT_DUMP.md:535:.\B0544_tmp\cmd1.txt:19:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:536:.\B0544_tmp\cmd1.txt:22:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:537:.\B0544_tmp\cmd1.txt:33:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:538:.\B0544_tmp\cmd1.txt:34:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:554:backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\B0544_CONTEXT_DUMP.md:555:backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:556:backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:571:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:575:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:581:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:585:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:597:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:602:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:623:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_CONTEXT_DUMP.md:624:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_CONTEXT_DUMP.md:636:.\backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\B0544_CONTEXT_DUMP.md:637:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:638:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:647:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:648:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:48:      "beat_scheduler": "celery.beat:PersistentScheduler",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:38:    "beat_scheduler": "celery.beat:PersistentScheduler",
.\backend\app\celery_app.py:195:    from app.tasks.beat_schedule import BEAT_SCHEDULE
.\backend\app\celery_app.py:196:    celery_app.conf.beat_schedule = BEAT_SCHEDULE
.\backend\app\celery_app.py:205:            "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
.\backend\app\celery_app.py:206:            "scheduled_tasks": list(celery_app.conf.beat_schedule.keys()) if celery_app.conf.beat_schedule else [],
.\backend\app\tasks\beat_schedule.py:33:def build_beat_schedule() -> Dict[str, Dict[str, Any]]:
.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\backend\app\tasks\beat_schedule.py:55:BEAT_SCHEDULE = build_beat_schedule()
.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:129:    'beat_schedule_loaded': bool(celery_app.conf.beat_schedule),
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:130:    'task_count': len(celery_app.conf.beat_schedule or {}),
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:133:        for name, entry in (celery_app.conf.beat_schedule or {}).items()
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:138:  "beat_schedule_loaded": true,
.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\docs\evidence\b054-forensic-readiness-evidence.md:634:   - **No `beat_schedule` key in conf.update()**
.\docs\evidence\b054-forensic-readiness-evidence.md:635:   - **Missing:** `beat_schedule=BEAT_SCHEDULE` assignment
.\docs\evidence\b054-forensic-readiness-evidence.md:953:- **Required Fix:** Load beat_schedule into celery_app.conf AND start Beat process (or use alternative scheduler)
.\docs\evidence\b054-forensic-readiness-evidence.md:978:2. **G11 BLOCKER addressed:** Load beat_schedule and deploy Beat process OR use alternative scheduling
.\docs\evidence\b054-forensic-readiness-evidence.md:993:2. **Fix G11:** Add `celery_app.conf.beat_schedule = BEAT_SCHEDULE` in celery_app.py:154
.\scripts\ci\zero_drift_v3_2.sh:132:    "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
.\scripts\ci\zero_drift_v3_2.sh:133:    "task_count": len(celery_app.conf.beat_schedule or {}),
.\scripts\ci\zero_drift_v3_2.sh:134:    "tasks": {name: {"task": entry["task"], "schedule": str(entry["schedule"])} for name, entry in (celery_app.conf.beat_schedule or {}).items()},
.\scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
```

### Runtime files discovery

Command:

```
Get-ChildItem -Recurse -File -Include "docker-compose*.yml","compose*.yml","Makefile","Procfile" . | ForEach-Object { $_.FullName }
```

Output:

```
C:\Users\ayewhy\II SKELDIR II\frontend\node_modules\sort-by\Makefile
C:\Users\ayewhy\II SKELDIR II\node_modules\delayed-stream\Makefile
C:\Users\ayewhy\II SKELDIR II\node_modules\foreach\Makefile
C:\Users\ayewhy\II SKELDIR II\node_modules\json-pointer\Makefile
C:\Users\ayewhy\II SKELDIR II\node_modules\lunr\Makefile
C:\Users\ayewhy\II SKELDIR II\docker-compose.component-dev.yml
C:\Users\ayewhy\II SKELDIR II\docker-compose.mock.yml
C:\Users\ayewhy\II SKELDIR II\Makefile
C:\Users\ayewhy\II SKELDIR II\Procfile
```

### Celery entrypoints in runtime files

Command:

```
rg -n "celery" -S docker-compose*.yml compose*.yml Makefile Procfile scripts 2>$null
```

Output:

```
Procfile:8:#   - worker: Celery background worker
Procfile:20:worker: cd backend && celery -A app.tasks worker --loglevel=info
scripts\r6\r6_context_gathering.py:24:from celery import __version__ as celery_version
scripts\r6\r6_context_gathering.py:25:from celery.result import AsyncResult
scripts\r6\r6_context_gathering.py:28:from app.celery_app import celery_app  # noqa: E402
scripts\r6\r6_context_gathering.py:94:def _celery_cli(base_args: list[str]) -> str:
scripts\r6\r6_context_gathering.py:95:    command = ["celery", "-A", "app.celery_app.celery_app"] + base_args
scripts\r6\r6_context_gathering.py:140:    conf = celery_app.conf
scripts\r6\r6_context_gathering.py:144:    for task_name, task in celery_app.tasks.items():
scripts\r6\r6_context_gathering.py:145:        if task_name.startswith("celery.") or task_name.startswith("kombu."):
scripts\r6\r6_context_gathering.py:274:        f"- task_time_limit: {conf.get('task_time_limit')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:275:        f"- task_soft_time_limit: {conf.get('task_soft_time_limit')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:276:        f"- task_acks_late: {conf.get('task_acks_late')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:277:        f"- task_reject_on_worker_lost: {conf.get('task_reject_on_worker_lost')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:278:        f"- task_acks_on_failure_or_timeout: {conf.get('task_acks_on_failure_or_timeout')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:279:        f"- worker_prefetch_multiplier: {conf.get('worker_prefetch_multiplier')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:280:        f"- worker_max_tasks_per_child: {conf.get('worker_max_tasks_per_child')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:281:        f"- worker_max_memory_per_child: {conf.get('worker_max_memory_per_child')} (evidence: R6_CELERY_INSPECT_CONF.json)",
scripts\r6\r6_context_gathering.py:300:            result = celery_app.send_task(
scripts\r6\r6_context_gathering.py:314:    result = celery_app.send_task(
scripts\r6\r6_context_gathering.py:352:    result = celery_app.send_task(
scripts\r6\r6_context_gathering.py:398:        celery_app.send_task(
scripts\r6\r6_context_gathering.py:406:        celery_app.send_task(
scripts\r6\r6_context_gathering.py:466:        result = celery_app.send_task(
scripts\r6\r6_context_gathering.py:535:        "celery": {"version": celery_version},
scripts\r6\r6_context_gathering.py:544:        output_dir / "R6_CELERY_REPORT.log",
scripts\r6\r6_context_gathering.py:545:        _celery_cli(["report"]),
scripts\r6\r6_context_gathering.py:550:        output_dir / "R6_CELERY_INSPECT_CONF.log",
scripts\r6\r6_context_gathering.py:551:        _celery_cli(["inspect", "conf"]),
scripts\r6\r6_context_gathering.py:556:        output_dir / "R6_CELERY_INSPECT_STATS.log",
scripts\r6\r6_context_gathering.py:557:        _celery_cli(["inspect", "stats"]),
scripts\r6\r6_context_gathering.py:563:        _celery_cli(["inspect", "active_queues"]),
scripts\r6\r6_context_gathering.py:569:        _celery_cli(["inspect", "registered"]),
scripts\r6\r6_context_gathering.py:577:    _write_json(output_dir / "R6_CELERY_INSPECT_CONF.json", snapshot, sha=sha, timestamp=timestamp)
scripts\r6\r6_context_gathering.py:579:    inspector = celery_app.control.inspect(timeout=5)
scripts\r6\r6_context_gathering.py:589:    _write_json(output_dir / "R6_CELERY_INSPECT_STATS.json", stats, sha=sha, timestamp=timestamp)
scripts\r6\r6_context_gathering.py:595:            "tasks": sorted(celery_app.tasks.keys()),
scripts\r6\r6_context_gathering.py:622:    conf = celery_app.conf
scripts\r4\render_r4_summary.py:99:    gate_fix_0 = bool(env.get("candidate_sha") and env.get("tenants") and env.get("celery") and verdicts and evidence_pack)
scripts\r4\render_r4_summary.py:101:    celery_env = env.get("celery", {}) if isinstance(env.get("celery", {}), dict) else {}
scripts\r4\render_r4_summary.py:102:    broker_scheme = str(celery_env.get("broker_scheme") or "")
scripts\r4\render_r4_summary.py:103:    backend_scheme = str(celery_env.get("result_backend_scheme") or "")
scripts\r4\render_r4_summary.py:104:    broker_hash = str(celery_env.get("broker_dsn_sha256") or "")
scripts\r4\render_r4_summary.py:105:    backend_hash = str(celery_env.get("result_backend_dsn_sha256") or "")
scripts\r4\render_r4_summary.py:166:            f"- `acks_late` = `{env.get('celery', {}).get('acks_late')}`",
scripts\r4\render_r4_summary.py:167:            f"- `reject_on_worker_lost` = `{env.get('celery', {}).get('reject_on_worker_lost')}`",
scripts\r4\render_r4_summary.py:168:            f"- `acks_on_failure_or_timeout` = `{env.get('celery', {}).get('acks_on_failure_or_timeout')}`",
scripts\r4\render_r4_summary.py:169:            f"- `prefetch_multiplier` = `{env.get('celery', {}).get('prefetch_multiplier')}`",
scripts\r4\worker_failure_semantics.py:4:Authoritative proof harness: runs against a real Postgres + real Celery worker fabric
scripts\r4\worker_failure_semantics.py:29:from app.celery_app import celery_app  # noqa: E402
scripts\r4\worker_failure_semantics.py:41:def _kill_stray_celery_workers() -> int:
scripts\r4\worker_failure_semantics.py:43:    Best-effort cleanup: ensure no orphaned Celery worker processes remain between scenarios.
scripts\r4\worker_failure_semantics.py:64:        if "celery" not in args or "app.celery_app.celery_app" not in args or " worker" not in args:
scripts\r4\worker_failure_semantics.py:183:            "celery",
scripts\r4\worker_failure_semantics.py:185:            "app.celery_app.celery_app",
scripts\r4\worker_failure_semantics.py:308:    raise TimeoutError("Timed out waiting for Celery results")
scripts\r4\worker_failure_semantics.py:315:            r = celery_app.send_task("app.tasks.housekeeping.ping", kwargs={"fail": False})
scripts\r4\worker_failure_semantics.py:651:        celery_app.send_task(
scripts\r4\worker_failure_semantics.py:737:        celery_app.send_task(
scripts\r4\worker_failure_semantics.py:860:    r = celery_app.send_task(
scripts\r4\worker_failure_semantics.py:915:    runaway = celery_app.send_task(
scripts\r4\worker_failure_semantics.py:928:        celery_app.send_task(
scripts\r4\worker_failure_semantics.py:983:    r = celery_app.send_task(
scripts\r4\worker_failure_semantics.py:1047:    broker_dsn = str(getattr(celery_app.conf, "broker_url", "") or "")
scripts\r4\worker_failure_semantics.py:1048:    backend_dsn = str(getattr(celery_app.conf, "result_backend", "") or "")
scripts\r4\worker_failure_semantics.py:1089:    poison_worker = WorkerSupervisor(concurrency=concurrency, pool=poison_pool, log_prefix="celery_harness_worker_poison")
scripts\r4\worker_failure_semantics.py:1100:    broker_transport_options = getattr(celery_app.conf, "broker_transport_options", None)
scripts\r4\worker_failure_semantics.py:1102:        "visibility_timeout_s": int(_env("CELERY_BROKER_VISIBILITY_TIMEOUT_S", "0") or 0),
scripts\r4\worker_failure_semantics.py:1104:            _env("CELERY_BROKER_RECOVERY_SWEEP_INTERVAL_S", _env("CELERY_BROKER_POLLING_INTERVAL_S", "0.0")) or 0.0
scripts\r4\worker_failure_semantics.py:1106:        "task_name_filter": _env("CELERY_BROKER_RECOVERY_TASK_NAME_FILTER", ""),
scripts\r4\worker_failure_semantics.py:1113:        "celery": {
scripts\r4\worker_failure_semantics.py:1120:            "acks_late": bool(getattr(celery_app.conf, "task_acks_late", False)),
scripts\r4\worker_failure_semantics.py:1121:            "reject_on_worker_lost": bool(getattr(celery_app.conf, "task_reject_on_worker_lost", False)),
scripts\r4\worker_failure_semantics.py:1122:            "acks_on_failure_or_timeout": bool(getattr(celery_app.conf, "task_acks_on_failure_or_timeout", False)),
scripts\r4\worker_failure_semantics.py:1123:            "prefetch_multiplier": int(getattr(celery_app.conf, "worker_prefetch_multiplier", 0) or 0),
scripts\r4\worker_failure_semantics.py:1137:                "prefetch": config_dump["celery"]["prefetch_multiplier"],
scripts\r4\worker_failure_semantics.py:1138:                "acks_late": config_dump["celery"]["acks_late"],
scripts\r4\worker_failure_semantics.py:1139:                "reject_on_worker_lost": config_dump["celery"]["reject_on_worker_lost"],
scripts\r4\worker_failure_semantics.py:1140:                "acks_on_failure_or_timeout": config_dump["celery"]["acks_on_failure_or_timeout"],
scripts\r4\worker_failure_semantics.py:1190:                    _kill_stray_celery_workers()
scripts\r4\worker_failure_semantics.py:1198:                        concurrency=crash_concurrency, pool=crash_pool, log_prefix="celery_harness_worker_crash"
scripts\r4\worker_failure_semantics.py:1223:                    _kill_stray_celery_workers()
scripts\r4\worker_failure_semantics.py:1231:                        concurrency=concurrency, pool=main_pool, log_prefix="celery_harness_worker_main"
scripts\r4\worker_failure_semantics.py:1288:                _kill_stray_celery_workers()
scripts\r4\worker_failure_semantics.py:1291:                    _kill_stray_celery_workers()
scripts\r4\worker_failure_semantics.py:1294:                    _kill_stray_celery_workers()
scripts\ci\zero_drift_v3_2.sh:124:export CELERY_BROKER_URL="sqla+postgresql://app_user:app_user@${PGHOST}:${PGPORT}/skeldir_zg_fresh"
scripts\ci\zero_drift_v3_2.sh:125:export CELERY_RESULT_BACKEND="db+postgresql://app_user:app_user@${PGHOST}:${PGPORT}/skeldir_zg_fresh"
scripts\ci\zero_drift_v3_2.sh:129:from app.celery_app import celery_app
scripts\ci\zero_drift_v3_2.sh:132:    "beat_schedule_loaded": bool(celery_app.conf.beat_schedule),
scripts\ci\zero_drift_v3_2.sh:133:    "task_count": len(celery_app.conf.beat_schedule or {}),
scripts\ci\zero_drift_v3_2.sh:134:    "tasks": {name: {"task": entry["task"], "schedule": str(entry["schedule"])} for name, entry in (celery_app.conf.beat_schedule or {}).items()},
scripts\ci\zero_drift_v3_2.sh:137:timeout 20 celery -A app.celery_app.celery_app beat --loglevel=INFO --pidfile= --schedule=/tmp/zg_beat_schedule --max-interval=2 > /tmp/zg_beat.log 2>&1 || true
```

### Competing scheduler search (cron/APScheduler)

Command:

```
rg -n "cron|crontab|APScheduler|schedule\.every|while True|sleep\(|timer|Periodic|background job" -S --glob "!**/.git/**" --glob "!**/node_modules/**" backend scripts .
```

Output:

```
.\B0.5.2_Context_Inventory_Baseline.md:181:2. **Worker-level DLQ schema**: Postgres tables + routing convention for failed background jobs, ensuring deterministic failure capture and replay.
.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:55:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:58:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:62:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:63:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:65:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:68:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:71:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_CONTEXT_DUMP.md:72:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_CONTEXT_DUMP.md:73:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:76:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:87:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:88:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:113:backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1503:- Test environment: Periodic manual cleanup via direct SQL (bypass trigger using superuser)
.\B0544_CONTEXT_DUMP.md:114:backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1754:-- Periodic archival job (weekly cron)
.\B0544_CONTEXT_DUMP.md:257:backend\app\middleware\pii_stripping.py:10:- Layer 3 (Audit): Periodic scanning detects residual contamination
.\B0544_CONTEXT_DUMP.md:302:backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:499:### 6) Competing scheduler search (cron/APScheduler/loop)
.\B0544_CONTEXT_DUMP.md:504:rg -n "cron|crontab|APScheduler|schedule\.every|while True|sleep\(|timer|Periodic|background job" -S --glob "!**/.git/**" --glob "!**/node_modules/**" backend scripts .
.\B0544_CONTEXT_DUMP.md:510:.\B0.5.2_Context_Inventory_Baseline.md:181:2. **Worker-level DLQ schema**: Postgres tables + routing convention for failed background jobs, ensuring deterministic failure capture and replay.
.\B0544_CONTEXT_DUMP.md:511:scripts\ci\zero_drift_v3_2.sh:153:        await asyncio.sleep(duration)
.\B0544_CONTEXT_DUMP.md:512:scripts\ci\zero_drift_v3_2.sh:161:    await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:513:scripts\r4\worker_failure_semantics.py:307:        time.sleep(0.25)
.\B0544_CONTEXT_DUMP.md:514:scripts\r4\worker_failure_semantics.py:318:            time.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:515:scripts\r4\worker_failure_semantics.py:553:        await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:516:scripts\r4\worker_failure_semantics.py:604:        await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:517:scripts\r4\worker_failure_semantics.py:675:        await asyncio.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:518:scripts\r4\worker_failure_semantics.py:922:    time.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:519:scripts\r4\worker_failure_semantics.py:943:        await asyncio.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:520:scripts\r6\r6_context_gathering.py:307:            time.sleep(1)
.\B0544_CONTEXT_DUMP.md:521:scripts\r3\ingestion_under_fire.py:108:            await asyncio.sleep(delay_s)
.\B0544_CONTEXT_DUMP.md:522:scripts\r3\ingestion_under_fire.py:208:        await asyncio.sleep(delay_s)
.\B0544_CONTEXT_DUMP.md:523:.\B0544_tmp\cmd2.txt:3:backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1503:- Test environment: Periodic manual cleanup via direct SQL (bypass trigger using superuser)
.\B0544_CONTEXT_DUMP.md:524:.\B0544_tmp\cmd2.txt:4:backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1754:-- Periodic archival job (weekly cron)
.\B0544_CONTEXT_DUMP.md:525:.\B0544_tmp\cmd2.txt:147:backend\app\middleware\pii_stripping.py:10:- Layer 3 (Audit): Periodic scanning detects residual contamination
.\B0544_CONTEXT_DUMP.md:526:.\B0544_tmp\cmd2.txt:192:backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:527:.\B0544_tmp\cmd1.txt:1:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:528:.\B0544_tmp\cmd1.txt:4:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:529:.\B0544_tmp\cmd1.txt:8:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:530:.\B0544_tmp\cmd1.txt:9:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:531:.\B0544_tmp\cmd1.txt:11:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:532:.\B0544_tmp\cmd1.txt:14:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:533:.\B0544_tmp\cmd1.txt:17:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_CONTEXT_DUMP.md:534:.\B0544_tmp\cmd1.txt:18:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_CONTEXT_DUMP.md:535:.\B0544_tmp\cmd1.txt:19:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:536:.\B0544_tmp\cmd1.txt:22:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:537:.\B0544_tmp\cmd1.txt:33:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:538:.\B0544_tmp\cmd1.txt:34:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:539:.\DIRECTOR_BRIEFING_VALIDATION_RESULTS.md:241:????????? tasks/ (background jobs)
.\B0544_CONTEXT_DUMP.md:540:backend\B044_EXECUTION_SUMMARY.md:517:-- Weekly cron job
.\B0544_CONTEXT_DUMP.md:541:backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1503:- Test environment: Periodic manual cleanup via direct SQL (bypass trigger using superuser)
.\B0544_CONTEXT_DUMP.md:542:backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1754:-- Periodic archival job (weekly cron)
.\B0544_CONTEXT_DUMP.md:543:.\tests\contract\test_mock_integrity.py:231:                time.sleep(RETRY_DELAY * (attempt + 1))
.\B0544_CONTEXT_DUMP.md:544:backend\app\tasks\r6_resource_governance.py:144:        while True:
.\B0544_CONTEXT_DUMP.md:545:backend\app\tasks\r6_resource_governance.py:145:            time.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:546:backend\app\tasks\r6_resource_governance.py:159:        while True:
.\B0544_CONTEXT_DUMP.md:547:backend\app\tasks\r6_resource_governance.py:160:            time.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:548:backend\app\tasks\r6_resource_governance.py:211:    time.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:549:backend\app\tasks\r6_resource_governance.py:249:    time.sleep(float(sleep_s))
.\B0544_CONTEXT_DUMP.md:550:backend\app\tasks\r4_failure_semantics.py:250:        time.sleep(3600)
.\B0544_CONTEXT_DUMP.md:551:backend\app\tasks\r4_failure_semantics.py:301:def runaway_sleep(self, *, tenant_id: str, correlation_id: str, sleep_s: int) -> dict[str, str]:
.\B0544_CONTEXT_DUMP.md:552:backend\app\tasks\r4_failure_semantics.py:318:        time.sleep(sleep_s)
.\B0544_CONTEXT_DUMP.md:553:backend\app\tasks\context.py:55:        time.sleep(0.01)
.\B0544_CONTEXT_DUMP.md:554:backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\B0544_CONTEXT_DUMP.md:555:backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:556:backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:557:.\artifacts_vt_run3\phase-VALUE_04-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:558:backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:559:backend\app\middleware\pii_stripping.py:10:- Layer 3 (Audit): Periodic scanning detects residual contamination
.\B0544_CONTEXT_DUMP.md:560:.\scripts\r6\r6_context_gathering.py:307:            time.sleep(1)
.\B0544_CONTEXT_DUMP.md:561:.\scripts\r4\worker_failure_semantics.py:307:        time.sleep(0.25)
.\B0544_CONTEXT_DUMP.md:562:.\scripts\r4\worker_failure_semantics.py:318:            time.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:563:.\scripts\r4\worker_failure_semantics.py:553:        await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:564:.\scripts\r4\worker_failure_semantics.py:604:        await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:565:.\scripts\r4\worker_failure_semantics.py:675:        await asyncio.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:566:.\scripts\r4\worker_failure_semantics.py:922:    time.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:567:.\scripts\r4\worker_failure_semantics.py:943:        await asyncio.sleep(0.5)
.\B0544_CONTEXT_DUMP.md:568:.\scripts\r3\ingestion_under_fire.py:108:            await asyncio.sleep(delay_s)
.\B0544_CONTEXT_DUMP.md:569:.\scripts\r3\ingestion_under_fire.py:208:        await asyncio.sleep(delay_s)
.\B0544_CONTEXT_DUMP.md:570:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:44:      "beat_cron_starting_deadline": null,
.\B0544_CONTEXT_DUMP.md:571:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:572:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:282:      "worker_timer": null,
.\B0544_CONTEXT_DUMP.md:573:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:283:      "worker_timer_precision": 1.0
.\B0544_CONTEXT_DUMP.md:574:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:34:    "beat_cron_starting_deadline": null,
.\B0544_CONTEXT_DUMP.md:575:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:576:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:272:    "worker_timer": null,
.\B0544_CONTEXT_DUMP.md:577:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:273:    "worker_timer_precision": 1.0
.\B0544_CONTEXT_DUMP.md:578:.\backend\scripts\repro_fixture_ping.py:67:            time.sleep(poll_interval)
.\B0544_CONTEXT_DUMP.md:579:.\monitoring\alerts\pii-alerts.yml:74:          action: "Check audit scan scheduler configuration, verify cron job or scheduled task"
.\B0544_CONTEXT_DUMP.md:580:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:44:      "beat_cron_starting_deadline": null,
.\B0544_CONTEXT_DUMP.md:581:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:582:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:282:      "worker_timer": null,
.\B0544_CONTEXT_DUMP.md:583:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:283:      "worker_timer_precision": 1.0
.\B0544_CONTEXT_DUMP.md:584:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:34:    "beat_cron_starting_deadline": null,
.\B0544_CONTEXT_DUMP.md:585:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:586:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:272:    "worker_timer": null,
.\B0544_CONTEXT_DUMP.md:587:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:273:    "worker_timer_precision": 1.0
.\B0544_CONTEXT_DUMP.md:588:.\docs\archive\FRONTEND_IMPLEMENTATION_SPECIFICATION.md:133:- Clears timers on unmount to avoid memory leaks.
.\B0544_CONTEXT_DUMP.md:589:backend\app\celery_app.py:305:        while True:
.\B0544_CONTEXT_DUMP.md:590:backend\app\celery_app.py:319:            time.sleep(sweep_interval_s)
.\B0544_CONTEXT_DUMP.md:591:.\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:592:.\frontend\src\hooks\useTokenManager.tsx:29:  const refP = useRef<Promise<void> | null>(null), timer = useRef<number | null>(null);
.\B0544_CONTEXT_DUMP.md:593:.\frontend\src\hooks\useTokenManager.tsx:32:  const clearToken = () => { setT(null); setE(null); setErr(null); if (timer.current) clearTimeout(timer.current); };
.\B0544_CONTEXT_DUMP.md:594:.\frontend\src\hooks\useTokenManager.tsx:52:    if (d > 0) timer.current = window.setTimeout(refreshToken, d);
.\B0544_CONTEXT_DUMP.md:595:.\frontend\src\hooks\useTokenManager.tsx:54:    return () => { if (timer.current) clearTimeout(timer.current); };
.\B0544_CONTEXT_DUMP.md:596:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:44:      "beat_cron_starting_deadline": null,
.\B0544_CONTEXT_DUMP.md:597:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:598:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:289:      "worker_timer": null,
.\B0544_CONTEXT_DUMP.md:599:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:290:      "worker_timer_precision": 1.0
.\B0544_CONTEXT_DUMP.md:600:.\frontend\src\hooks\useReconciliationAutoRefresh.ts:68:  // Countdown timer for "Next refresh in X seconds"
.\B0544_CONTEXT_DUMP.md:601:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:34:    "beat_cron_starting_deadline": null,
.\B0544_CONTEXT_DUMP.md:602:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_CONTEXT_DUMP.md:603:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:279:    "worker_timer": null,
.\B0544_CONTEXT_DUMP.md:604:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:280:    "worker_timer_precision": 1.0
.\B0544_CONTEXT_DUMP.md:605:.\backend\B044_EXECUTION_SUMMARY.md:517:-- Weekly cron job
.\B0544_CONTEXT_DUMP.md:606:.\frontend\src\hooks\use-file-downloader.ts:61:      if (currentDownloadTokenRef.current === downloadToken) { const timer = fallbackTimersRef.current.get(downloadToken); if (timer) { clearTimeout(timer); fallbackTimersRef.current.delete(downloadToken); } setIsDownloading(false); }
.\B0544_CONTEXT_DUMP.md:607:.\frontend\src\hooks\use-file-downloader.ts:63:      if (currentDownloadTokenRef.current === downloadToken) { const timer = fallbackTimersRef.current.get(downloadToken); if (timer) { clearTimeout(timer); fallbackTimersRef.current.delete(downloadToken); } }
.\B0544_CONTEXT_DUMP.md:608:.\frontend\src\hooks\use-file-downloader.ts:88:  useEffect(() => () => { abortControllerRef.current?.abort(); blobUrlsRef.current.forEach(url => URL.revokeObjectURL(url)); revokeTimersRef.current.forEach(timer => clearTimeout(timer)); fallbackTimersRef.current.forEach(timer => clearTimeout(timer)); }, []);
.\B0544_CONTEXT_DUMP.md:609:.\docs\archive\completed-phases\b0.3\B0.3_FORENSIC_ANALYSIS_RESPONSE.md:775:- External scheduler (cron, Kubernetes jobs)
.\B0544_CONTEXT_DUMP.md:610:.\backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1503:- Test environment: Periodic manual cleanup via direct SQL (bypass trigger using superuser)
.\B0544_CONTEXT_DUMP.md:611:.\backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1754:-- Periodic archival job (weekly cron)
.\B0544_CONTEXT_DUMP.md:612:.\frontend\src\hooks\use-auto-dismiss.ts:16:  const timerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
.\B0544_CONTEXT_DUMP.md:613:.\frontend\src\hooks\use-auto-dismiss.ts:35:    if (timerRef.current) clearTimeout(timerRef.current);
.\B0544_CONTEXT_DUMP.md:614:.\frontend\src\hooks\use-auto-dismiss.ts:48:    timerRef.current = setTimeout(() => !dismissedRef.current && (dismissedRef.current = true, onDismissRef.current()), duration - pausedAtRef.current);
.\B0544_CONTEXT_DUMP.md:615:.\frontend\src\hooks\use-auto-dismiss.ts:55:    if (timerRef.current) clearTimeout(timerRef.current);
.\B0544_CONTEXT_DUMP.md:616:.\frontend\src\hooks\use-auto-dismiss.ts:60:    timerRef.current = setTimeout(() => !dismissedRef.current && (dismissedRef.current = true, onDismissRef.current()), duration);
.\B0544_CONTEXT_DUMP.md:617:.\frontend\src\hooks\use-auto-dismiss.ts:65:    if (timerRef.current) clearTimeout(timerRef.current);
.\B0544_CONTEXT_DUMP.md:618:.\frontend\src\hooks\use-auto-dismiss.ts:73:    timerRef.current = setTimeout(() => !dismissedRef.current && (dismissedRef.current = true, onDismissRef.current()), duration);
.\B0544_CONTEXT_DUMP.md:619:.\frontend\src\hooks\use-auto-dismiss.ts:75:    return () => { if (timerRef.current) clearTimeout(timerRef.current); if (rafRef.current) cancelAnimationFrame(rafRef.current); };
.\B0544_CONTEXT_DUMP.md:620:.\docs\archive\completed-phases\b0.1\B0.1_PHASE_FORENSIC_EVALUATION_RESPONSE.md:761:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:621:backend\test_eg6_serialization.py:36:            await asyncio.sleep(delay_sec)
.\B0544_CONTEXT_DUMP.md:622:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:660:- No external DB-level cron dependencies (e.g., `pg_cron`)
.\B0544_CONTEXT_DUMP.md:623:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_CONTEXT_DUMP.md:624:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_CONTEXT_DUMP.md:625:.\docs\governance\DATA_PRIVACY_LIFECYCLE.md:96:**Mechanism**: Periodic batch scanning of JSONB surfaces to detect residual PII contamination
.\B0544_CONTEXT_DUMP.md:626:.\backend\app\tasks\r6_resource_governance.py:144:        while True:
.\B0544_CONTEXT_DUMP.md:627:.\backend\app\tasks\r6_resource_governance.py:145:            time.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:628:.\backend\app\tasks\r6_resource_governance.py:159:        while True:
.\B0544_CONTEXT_DUMP.md:629:.\backend\app\tasks\r6_resource_governance.py:160:            time.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:630:.\backend\app\tasks\r6_resource_governance.py:211:    time.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:631:.\backend\app\tasks\r6_resource_governance.py:249:    time.sleep(float(sleep_s))
.\B0544_CONTEXT_DUMP.md:632:.\backend\app\tasks\r4_failure_semantics.py:250:        time.sleep(3600)
.\B0544_CONTEXT_DUMP.md:633:.\backend\app\tasks\r4_failure_semantics.py:301:def runaway_sleep(self, *, tenant_id: str, correlation_id: str, sleep_s: int) -> dict[str, str]:
.\B0544_CONTEXT_DUMP.md:634:.\backend\app\tasks\r4_failure_semantics.py:318:        time.sleep(sleep_s)
.\B0544_CONTEXT_DUMP.md:635:.\backend\app\tasks\context.py:55:        time.sleep(0.01)
.\B0544_CONTEXT_DUMP.md:636:.\backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\B0544_CONTEXT_DUMP.md:637:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:638:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:639:.\artifacts_vt_run3\phase-VALUE_03-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:640:.\scripts\ci\zero_drift_v3_2.sh:153:        await asyncio.sleep(duration)
.\B0544_CONTEXT_DUMP.md:641:.\scripts\ci\zero_drift_v3_2.sh:161:    await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:642:backend\tests\test_b0542_refresh_executor.py:37:        await asyncio.sleep(0.25)
.\B0544_CONTEXT_DUMP.md:643:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:142:    "pii-audit-scanner": {"task": "app.tasks.maintenance.scan_for_pii_contamination", "schedule": "<crontab: 0 4 * * * (m/h/dM/MY/d)>"},
.\B0544_CONTEXT_DUMP.md:644:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:143:    "enforce-data-retention": {"task": "app.tasks.maintenance.enforce_data_retention", "schedule": "<crontab: 0 3 * * * (m/h/dM/MY/d)>"}
.\B0544_CONTEXT_DUMP.md:645:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:173:        await asyncio.sleep(duration)
.\B0544_CONTEXT_DUMP.md:646:.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:182:    await asyncio.sleep(0.2)
.\B0544_CONTEXT_DUMP.md:647:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_CONTEXT_DUMP.md:648:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_CONTEXT_DUMP.md:649:.\docs\evidence\b054-forensic-readiness-evidence.md:665:- B0.5.4 implementation must decide: Enable Beat or use alternative scheduling (e.g., cron, CI scheduled workflow)
.\B0544_CONTEXT_DUMP.md:650:.\docs\evidence\b054-forensic-readiness-evidence.md:1003:8. **Decision:** Beat scheduling OR CI cron OR both?
.\B0544_CONTEXT_DUMP.md:651:backend\tests\test_b051_celery_foundation.py:152:            time.sleep(2)
.\B0544_CONTEXT_DUMP.md:652:backend\tests\test_b051_celery_foundation.py:251:        time.sleep(1)
.\B0544_CONTEXT_DUMP.md:653:.\backend\app\middleware\pii_stripping.py:10:- Layer 3 (Audit): Periodic scanning detects residual contamination
.\B0544_CONTEXT_DUMP.md:654:.\backend\app\celery_app.py:305:        while True:
.\B0544_CONTEXT_DUMP.md:655:.\backend\app\celery_app.py:319:            time.sleep(sweep_interval_s)
.\B0544_CONTEXT_DUMP.md:656:.\backend\test_eg6_serialization.py:36:            await asyncio.sleep(delay_sec)
.\B0544_CONTEXT_DUMP.md:657:backend\scripts\repro_fixture_ping.py:67:            time.sleep(poll_interval)
.\B0544_CONTEXT_DUMP.md:658:.\frontend\src\components\icons\SkelderIcons.tsx:220:      {/* Clock/timer visualization */}
.\B0544_CONTEXT_DUMP.md:659:.\frontend\package-lock.json:2884:    "node_modules/@types/d3-timer": {
.\B0544_CONTEXT_DUMP.md:660:.\frontend\package-lock.json:2886:      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
.\B0544_CONTEXT_DUMP.md:661:.\frontend\package-lock.json:3736:    "node_modules/d3-timer": {
.\B0544_CONTEXT_DUMP.md:662:.\frontend\package-lock.json:3738:      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
.\B0544_CONTEXT_DUMP.md:663:.\frontend\package-lock.json:6081:        "@types/d3-timer": "^3.0.0",
.\B0544_CONTEXT_DUMP.md:664:.\frontend\package-lock.json:6088:        "d3-timer": "^3.0.1"
.\B0544_CONTEXT_DUMP.md:665:.\artifacts_vt_run3\phase-VALUE_01-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:666:.\frontend\src\components\dashboard\VerificationToast.tsx:21:    const timer = setTimeout(() => {
.\B0544_CONTEXT_DUMP.md:667:.\frontend\src\components\dashboard\VerificationToast.tsx:35:      clearTimeout(timer);
.\B0544_CONTEXT_DUMP.md:668:.\frontend\src\components\dashboard\VerificationToast.tsx:60:    const timer = setTimeout(onDismiss, 4000);
.\B0544_CONTEXT_DUMP.md:669:.\frontend\src\components\dashboard\VerificationToast.tsx:61:    return () => clearTimeout(timer);
.\B0544_CONTEXT_DUMP.md:670:.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:2884:    "node_modules/@types/d3-timer": {
.\B0544_CONTEXT_DUMP.md:671:.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:2886:      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
.\B0544_CONTEXT_DUMP.md:672:.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:3736:    "node_modules/d3-timer": {
.\B0544_CONTEXT_DUMP.md:673:.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:3738:      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
.\B0544_CONTEXT_DUMP.md:674:.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:6081:        "@types/d3-timer": "^3.0.0",
.\B0544_CONTEXT_DUMP.md:675:.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:6088:        "d3-timer": "^3.0.1"
.\B0544_CONTEXT_DUMP.md:676:.\artifacts_vt_run3\phase-VALUE_02-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\B0544_CONTEXT_DUMP.md:677:.\backend\tests\test_b051_celery_foundation.py:152:            time.sleep(2)
.\B0544_CONTEXT_DUMP.md:678:.\backend\tests\test_b051_celery_foundation.py:251:        time.sleep(1)
.\B0544_CONTEXT_DUMP.md:679:.\backend\tests\test_b0542_refresh_executor.py:37:        await asyncio.sleep(0.25)
.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_schedule_defs.txt:4:.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_schedule_defs.txt:5:.\B0544_CONTEXT_DUMP.md:55:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:8:.\B0544_CONTEXT_DUMP.md:58:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:12:.\B0544_CONTEXT_DUMP.md:62:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:13:.\B0544_CONTEXT_DUMP.md:63:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:15:.\B0544_CONTEXT_DUMP.md:65:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:18:.\B0544_CONTEXT_DUMP.md:68:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:21:.\B0544_CONTEXT_DUMP.md:71:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:22:.\B0544_CONTEXT_DUMP.md:72:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:23:.\B0544_CONTEXT_DUMP.md:73:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:26:.\B0544_CONTEXT_DUMP.md:76:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:37:.\B0544_CONTEXT_DUMP.md:87:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:38:.\B0544_CONTEXT_DUMP.md:88:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:93:.\B0544_CONTEXT_DUMP.md:527:.\B0544_tmp\cmd1.txt:1:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:94:.\B0544_CONTEXT_DUMP.md:528:.\B0544_tmp\cmd1.txt:4:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:95:.\B0544_CONTEXT_DUMP.md:529:.\B0544_tmp\cmd1.txt:8:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:96:.\B0544_CONTEXT_DUMP.md:530:.\B0544_tmp\cmd1.txt:9:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:97:.\B0544_CONTEXT_DUMP.md:531:.\B0544_tmp\cmd1.txt:11:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:98:.\B0544_CONTEXT_DUMP.md:532:.\B0544_tmp\cmd1.txt:14:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:99:.\B0544_CONTEXT_DUMP.md:533:.\B0544_tmp\cmd1.txt:17:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:100:.\B0544_CONTEXT_DUMP.md:534:.\B0544_tmp\cmd1.txt:18:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:101:.\B0544_CONTEXT_DUMP.md:535:.\B0544_tmp\cmd1.txt:19:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:102:.\B0544_CONTEXT_DUMP.md:536:.\B0544_tmp\cmd1.txt:22:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:103:.\B0544_CONTEXT_DUMP.md:537:.\B0544_tmp\cmd1.txt:33:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:104:.\B0544_CONTEXT_DUMP.md:538:.\B0544_tmp\cmd1.txt:34:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:105:.\B0544_CONTEXT_DUMP.md:554:backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\B0544_tmp\grep_schedule_defs.txt:106:.\B0544_CONTEXT_DUMP.md:555:backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:107:.\B0544_CONTEXT_DUMP.md:556:backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:108:.\B0544_CONTEXT_DUMP.md:571:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:109:.\B0544_CONTEXT_DUMP.md:575:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:110:.\B0544_CONTEXT_DUMP.md:581:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:111:.\B0544_CONTEXT_DUMP.md:585:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:112:.\B0544_CONTEXT_DUMP.md:597:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:113:.\B0544_CONTEXT_DUMP.md:602:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:114:.\B0544_CONTEXT_DUMP.md:623:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:115:.\B0544_CONTEXT_DUMP.md:624:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:116:.\B0544_CONTEXT_DUMP.md:636:.\backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\B0544_tmp\grep_schedule_defs.txt:117:.\B0544_CONTEXT_DUMP.md:637:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:118:.\B0544_CONTEXT_DUMP.md:638:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:119:.\B0544_CONTEXT_DUMP.md:647:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:120:.\B0544_CONTEXT_DUMP.md:648:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_schedule_defs.txt:146:.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\B0544_tmp\grep_schedule_defs.txt:147:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:150:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:153:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:156:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:159:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:162:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\B0544_tmp\grep_schedule_defs.txt:170:.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:171:.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:173:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:174:.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\B0544_tmp\grep_schedule_defs.txt:179:.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\B0544_tmp\grep_schedule_defs.txt:180:.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
scripts\ci\zero_drift_v3_2.sh:153:        await asyncio.sleep(duration)
scripts\ci\zero_drift_v3_2.sh:161:    await asyncio.sleep(0.2)
.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:2884:    "node_modules/@types/d3-timer": {
.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:2886:      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:3736:    "node_modules/d3-timer": {
.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:3738:      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:6081:        "@types/d3-timer": "^3.0.0",
.\artifacts\runtime_preflight\2025-12-24_7650d094\package-lock.json:6088:        "d3-timer": "^3.0.1"
scripts\r6\r6_context_gathering.py:307:            time.sleep(1)
.\tests\contract\test_mock_integrity.py:231:                time.sleep(RETRY_DELAY * (attempt + 1))
.\artifacts_vt_run3\phase-VALUE_04-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\backend\B044_EXECUTION_SUMMARY.md:517:-- Weekly cron job
.\B0544_tmp\grep_beat_entrypoints.txt:1:.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_beat_entrypoints.txt:42:.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_beat_entrypoints.txt:67:.\B0544_tmp\grep_schedule_defs.txt:146:.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\B0544_tmp\grep_beat_entrypoints.txt:81:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_beat_entrypoints.txt:133:.\B0544_CONTEXT_DUMP.md:499:### 6) Competing scheduler search (cron/APScheduler/loop)
.\B0544_tmp\grep_beat_entrypoints.txt:134:.\B0544_CONTEXT_DUMP.md:504:rg -n "cron|crontab|APScheduler|schedule\.every|while True|sleep\(|timer|Periodic|background job" -S --glob "!**/.git/**" --glob "!**/node_modules/**" backend scripts .
.\B0544_tmp\grep_beat_entrypoints.txt:135:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_beat_entrypoints.txt:160:.\B0544_CONTEXT_DUMP.md:780:No competing scheduler mechanism (cron/APScheduler/database scheduler) appears in code; only Celery Beat is present as the scheduling mechanism via backend/app/tasks/beat_schedule.py and celery_app.conf.beat_schedule. Beat entrypoints are found in the CI harness (scripts/ci/zero_drift_v3_2.sh) but not in Procfile/compose runtime. This suggests a split-brain risk is currently low in code, but runtime may be missing a beat process outside CI.
.\backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1503:- Test environment: Periodic manual cleanup via direct SQL (bypass trigger using superuser)
.\backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1754:-- Periodic archival job (weekly cron)
.\B0544_tmp\beat_schedule_dump.txt:1:{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}
backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\backend\test_eg6_serialization.py:36:            await asyncio.sleep(delay_sec)
scripts\r4\worker_failure_semantics.py:307:        time.sleep(0.25)
scripts\r4\worker_failure_semantics.py:318:            time.sleep(0.5)
scripts\r4\worker_failure_semantics.py:553:        await asyncio.sleep(0.2)
scripts\r4\worker_failure_semantics.py:604:        await asyncio.sleep(0.2)
scripts\r4\worker_failure_semantics.py:675:        await asyncio.sleep(0.5)
scripts\r4\worker_failure_semantics.py:922:    time.sleep(0.5)
scripts\r4\worker_failure_semantics.py:943:        await asyncio.sleep(0.5)
.\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\artifacts_vt_run3\phase-VALUE_02-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\backend\app\tasks\r6_resource_governance.py:144:        while True:
.\backend\app\tasks\r6_resource_governance.py:145:            time.sleep(0.2)
.\backend\app\tasks\r6_resource_governance.py:159:        while True:
.\backend\app\tasks\r6_resource_governance.py:160:            time.sleep(0.2)
.\backend\app\tasks\r6_resource_governance.py:211:    time.sleep(0.2)
.\backend\app\tasks\r6_resource_governance.py:249:    time.sleep(float(sleep_s))
.\backend\app\tasks\r4_failure_semantics.py:250:        time.sleep(3600)
.\backend\app\tasks\r4_failure_semantics.py:301:def runaway_sleep(self, *, tenant_id: str, correlation_id: str, sleep_s: int) -> dict[str, str]:
.\backend\app\tasks\r4_failure_semantics.py:318:        time.sleep(sleep_s)
scripts\r3\ingestion_under_fire.py:108:            await asyncio.sleep(delay_s)
scripts\r3\ingestion_under_fire.py:208:        await asyncio.sleep(delay_s)
.\backend\app\tasks\context.py:55:        time.sleep(0.01)
.\backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
.\backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
.\backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\monitoring\alerts\pii-alerts.yml:74:          action: "Check audit scan scheduler configuration, verify cron job or scheduled task"
.\backend\app\middleware\pii_stripping.py:10:- Layer 3 (Audit): Periodic scanning detects residual contamination
.\scripts\r6\r6_context_gathering.py:307:            time.sleep(1)
.\backend\tests\test_b0542_refresh_executor.py:37:        await asyncio.sleep(0.25)
.\scripts\r4\worker_failure_semantics.py:307:        time.sleep(0.25)
.\scripts\r4\worker_failure_semantics.py:318:            time.sleep(0.5)
.\scripts\r4\worker_failure_semantics.py:553:        await asyncio.sleep(0.2)
.\scripts\r4\worker_failure_semantics.py:604:        await asyncio.sleep(0.2)
.\scripts\r4\worker_failure_semantics.py:675:        await asyncio.sleep(0.5)
.\scripts\r4\worker_failure_semantics.py:922:    time.sleep(0.5)
.\scripts\r4\worker_failure_semantics.py:943:        await asyncio.sleep(0.5)
.\backend\app\celery_app.py:305:        while True:
.\backend\app\celery_app.py:319:            time.sleep(sweep_interval_s)
.\scripts\r3\ingestion_under_fire.py:108:            await asyncio.sleep(delay_s)
.\scripts\r3\ingestion_under_fire.py:208:        await asyncio.sleep(delay_s)
.\backend\tests\test_b051_celery_foundation.py:152:            time.sleep(2)
.\backend\tests\test_b051_celery_foundation.py:251:        time.sleep(1)
backend\scripts\repro_fixture_ping.py:67:            time.sleep(poll_interval)
.\backend\scripts\repro_fixture_ping.py:67:            time.sleep(poll_interval)
backend\B044_EXECUTION_SUMMARY.md:517:-- Weekly cron job
backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1503:- Test environment: Periodic manual cleanup via direct SQL (bypass trigger using superuser)
backend\B043_COMPLETE_TECHNICAL_SUMMARY.md:1754:-- Periodic archival job (weekly cron)
.\artifacts_vt_run3\phase-VALUE_01-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\frontend\src\hooks\use-auto-dismiss.ts:16:  const timerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
.\frontend\src\hooks\use-auto-dismiss.ts:35:    if (timerRef.current) clearTimeout(timerRef.current);
.\frontend\src\hooks\use-auto-dismiss.ts:48:    timerRef.current = setTimeout(() => !dismissedRef.current && (dismissedRef.current = true, onDismissRef.current()), duration - pausedAtRef.current);
.\frontend\src\hooks\use-auto-dismiss.ts:55:    if (timerRef.current) clearTimeout(timerRef.current);
.\frontend\src\hooks\use-auto-dismiss.ts:60:    timerRef.current = setTimeout(() => !dismissedRef.current && (dismissedRef.current = true, onDismissRef.current()), duration);
.\frontend\src\hooks\use-auto-dismiss.ts:65:    if (timerRef.current) clearTimeout(timerRef.current);
.\frontend\src\hooks\use-auto-dismiss.ts:73:    timerRef.current = setTimeout(() => !dismissedRef.current && (dismissedRef.current = true, onDismissRef.current()), duration);
.\frontend\src\hooks\use-auto-dismiss.ts:75:    return () => { if (timerRef.current) clearTimeout(timerRef.current); if (rafRef.current) cancelAnimationFrame(rafRef.current); };
.\frontend\src\hooks\useTokenManager.tsx:29:  const refP = useRef<Promise<void> | null>(null), timer = useRef<number | null>(null);
.\frontend\src\hooks\useTokenManager.tsx:32:  const clearToken = () => { setT(null); setE(null); setErr(null); if (timer.current) clearTimeout(timer.current); };
.\frontend\src\hooks\useTokenManager.tsx:52:    if (d > 0) timer.current = window.setTimeout(refreshToken, d);
.\frontend\src\hooks\useTokenManager.tsx:54:    return () => { if (timer.current) clearTimeout(timer.current); };
.\frontend\src\hooks\useReconciliationAutoRefresh.ts:68:  // Countdown timer for "Next refresh in X seconds"
backend\app\tasks\r6_resource_governance.py:144:        while True:
backend\app\tasks\r6_resource_governance.py:145:            time.sleep(0.2)
backend\app\tasks\r6_resource_governance.py:159:        while True:
backend\app\tasks\r6_resource_governance.py:160:            time.sleep(0.2)
backend\app\tasks\r6_resource_governance.py:211:    time.sleep(0.2)
backend\app\tasks\r6_resource_governance.py:249:    time.sleep(float(sleep_s))
backend\app\tasks\r4_failure_semantics.py:250:        time.sleep(3600)
backend\app\tasks\r4_failure_semantics.py:301:def runaway_sleep(self, *, tenant_id: str, correlation_id: str, sleep_s: int) -> dict[str, str]:
backend\app\tasks\r4_failure_semantics.py:318:        time.sleep(sleep_s)
backend\app\tasks\context.py:55:        time.sleep(0.01)
.\frontend\src\hooks\use-file-downloader.ts:61:      if (currentDownloadTokenRef.current === downloadToken) { const timer = fallbackTimersRef.current.get(downloadToken); if (timer) { clearTimeout(timer); fallbackTimersRef.current.delete(downloadToken); } setIsDownloading(false); }
.\frontend\src\hooks\use-file-downloader.ts:63:      if (currentDownloadTokenRef.current === downloadToken) { const timer = fallbackTimersRef.current.get(downloadToken); if (timer) { clearTimeout(timer); fallbackTimersRef.current.delete(downloadToken); } }
.\frontend\src\hooks\use-file-downloader.ts:88:  useEffect(() => () => { abortControllerRef.current?.abort(); blobUrlsRef.current.forEach(url => URL.revokeObjectURL(url)); revokeTimersRef.current.forEach(timer => clearTimeout(timer)); fallbackTimersRef.current.forEach(timer => clearTimeout(timer)); }, []);
backend\app\tasks\beat_schedule.py:12:from celery.schedules import crontab
backend\app\tasks\beat_schedule.py:43:            "schedule": crontab(hour=4, minute=0),
backend\app\tasks\beat_schedule.py:48:            "schedule": crontab(hour=3, minute=0),
.\artifacts_vt_run3\phase-VALUE_03-evidence\backend\validation\evidence\privacy\pii_middleware_implemented.txt:23:- Periodic batch scanning
.\DIRECTOR_BRIEFING_VALIDATION_RESULTS.md:241:????????? tasks/ (background jobs)
.\scripts\ci\zero_drift_v3_2.sh:153:        await asyncio.sleep(duration)
.\scripts\ci\zero_drift_v3_2.sh:161:    await asyncio.sleep(0.2)
backend\app\middleware\pii_stripping.py:10:- Layer 3 (Audit): Periodic scanning detects residual contamination
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:44:      "beat_cron_starting_deadline": null,
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:282:      "worker_timer": null,
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:283:      "worker_timer_precision": 1.0
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:34:    "beat_cron_starting_deadline": null,
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:272:    "worker_timer": null,
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:273:    "worker_timer_precision": 1.0
backend\test_eg6_serialization.py:36:            await asyncio.sleep(delay_sec)
backend\app\celery_app.py:305:        while True:
backend\app\celery_app.py:319:            time.sleep(sweep_interval_s)
.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:660:- No external DB-level cron dependencies (e.g., `pg_cron`)
.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:774:        "schedule": crontab(hour=4, minute=0),  # Daily at 4:00 AM UTC
.\docs\governance\PRIVACY_LIFECYCLE_IMPLEMENTATION.md:1085:        "schedule": crontab(hour=3, minute=0),  # Daily at 3:00 AM UTC
.\docs\governance\DATA_PRIVACY_LIFECYCLE.md:96:**Mechanism**: Periodic batch scanning of JSONB surfaces to detect residual PII contamination
backend\tests\test_b051_celery_foundation.py:152:            time.sleep(2)
backend\tests\test_b051_celery_foundation.py:251:        time.sleep(1)
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:44:      "beat_cron_starting_deadline": null,
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:282:      "worker_timer": null,
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:283:      "worker_timer_precision": 1.0
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:34:    "beat_cron_starting_deadline": null,
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:272:    "worker_timer": null,
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:273:    "worker_timer_precision": 1.0
backend\tests\test_b0542_refresh_executor.py:37:        await asyncio.sleep(0.25)
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:142:    "pii-audit-scanner": {"task": "app.tasks.maintenance.scan_for_pii_contamination", "schedule": "<crontab: 0 4 * * * (m/h/dM/MY/d)>"},
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:143:    "enforce-data-retention": {"task": "app.tasks.maintenance.enforce_data_retention", "schedule": "<crontab: 0 3 * * * (m/h/dM/MY/d)>"}
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:173:        await asyncio.sleep(duration)
.\docs\evidence\b0540-drift-remediation-preflight-evidence.md:182:    await asyncio.sleep(0.2)
.\docs\evidence\b054-forensic-readiness-evidence.md:620:             "schedule": crontab(hour=4, minute=0),
.\docs\evidence\b054-forensic-readiness-evidence.md:625:             "schedule": crontab(hour=3, minute=0),
.\docs\evidence\b054-forensic-readiness-evidence.md:665:- B0.5.4 implementation must decide: Enable Beat or use alternative scheduling (e.g., cron, CI scheduled workflow)
.\docs\evidence\b054-forensic-readiness-evidence.md:1003:8. **Decision:** Beat scheduling OR CI cron OR both?
.\docs\archive\FRONTEND_IMPLEMENTATION_SPECIFICATION.md:133:- Clears timers on unmount to avoid memory leaks.
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:44:      "beat_cron_starting_deadline": null,
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:46:      "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:289:      "worker_timer": null,
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:290:      "worker_timer_precision": 1.0
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:34:    "beat_cron_starting_deadline": null,
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:36:    "beat_schedule": "{'refresh-matviews-every-5-min': {'task': 'app.tasks.maintenance.refresh_all_matviews_global_legacy', 'schedule': 300.0, 'options': {'expires': 600}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:279:    "worker_timer": null,
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:280:    "worker_timer_precision": 1.0
.\frontend\src\components\icons\SkelderIcons.tsx:220:      {/* Clock/timer visualization */}
.\docs\archive\completed-phases\b0.3\B0.3_FORENSIC_ANALYSIS_RESPONSE.md:775:- External scheduler (cron, Kubernetes jobs)
.\frontend\package-lock.json:2884:    "node_modules/@types/d3-timer": {
.\frontend\package-lock.json:2886:      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
.\frontend\package-lock.json:3736:    "node_modules/d3-timer": {
.\frontend\package-lock.json:3738:      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
.\frontend\package-lock.json:6081:        "@types/d3-timer": "^3.0.0",
.\frontend\package-lock.json:6088:        "d3-timer": "^3.0.1"
.\docs\archive\completed-phases\b0.1\B0.1_PHASE_FORENSIC_EVALUATION_RESPONSE.md:761:- Periodic batch scanning
.\frontend\src\components\dashboard\VerificationToast.tsx:21:    const timer = setTimeout(() => {
.\frontend\src\components\dashboard\VerificationToast.tsx:35:      clearTimeout(timer);
.\frontend\src\components\dashboard\VerificationToast.tsx:60:    const timer = setTimeout(onDismiss, 4000);
.\frontend\src\components\dashboard\VerificationToast.tsx:61:    return () => clearTimeout(timer);
```

### Database scheduler search

Command:

```
rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
```

Output:

```
.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_schedule_defs.txt:4:.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_schedule_defs.txt:6:.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:9:.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:16:.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:19:.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:24:.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:27:.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:63:.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:65:.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:67:.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:69:.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:71:.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:73:.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:76:.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:78:.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:81:.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:83:.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:85:.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:87:.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_schedule_defs.txt:122:.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:123:.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:124:.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:125:.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:126:.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:127:.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:128:.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:129:.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:130:.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:131:.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:132:.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:133:.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:134:.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:135:.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:136:.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:137:.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:138:.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:139:.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:140:.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:141:.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:142:.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:143:.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:144:.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:145:.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:148:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:151:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:154:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:157:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:160:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_schedule_defs.txt:163:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_competing_scheduler.txt:2:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_competing_scheduler.txt:3:.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_competing_scheduler.txt:192:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_competing_scheduler.txt:194:.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_competing_scheduler.txt:195:.\B0544_tmp\grep_schedule_defs.txt:4:.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_competing_scheduler.txt:236:.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_competing_scheduler.txt:262:.\B0544_tmp\grep_beat_entrypoints.txt:1:.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_competing_scheduler.txt:263:.\B0544_tmp\grep_beat_entrypoints.txt:42:.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_competing_scheduler.txt:265:.\B0544_tmp\grep_beat_entrypoints.txt:81:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_competing_scheduler.txt:268:.\B0544_tmp\grep_beat_entrypoints.txt:135:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_beat_entrypoints.txt:1:.\B0544_tmp\grep_schedule_defs.txt:3:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_beat_entrypoints.txt:2:.\B0544_tmp\grep_schedule_defs.txt:6:.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:4:.\B0544_tmp\grep_schedule_defs.txt:9:.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:6:.\B0544_tmp\grep_schedule_defs.txt:16:.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:8:.\B0544_tmp\grep_schedule_defs.txt:19:.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:10:.\B0544_tmp\grep_schedule_defs.txt:24:.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:12:.\B0544_tmp\grep_schedule_defs.txt:27:.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:15:.\B0544_tmp\grep_schedule_defs.txt:63:.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:17:.\B0544_tmp\grep_schedule_defs.txt:65:.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:19:.\B0544_tmp\grep_schedule_defs.txt:67:.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:21:.\B0544_tmp\grep_schedule_defs.txt:69:.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:23:.\B0544_tmp\grep_schedule_defs.txt:71:.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:25:.\B0544_tmp\grep_schedule_defs.txt:73:.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:28:.\B0544_tmp\grep_schedule_defs.txt:76:.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:30:.\B0544_tmp\grep_schedule_defs.txt:78:.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:33:.\B0544_tmp\grep_schedule_defs.txt:81:.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:35:.\B0544_tmp\grep_schedule_defs.txt:83:.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:37:.\B0544_tmp\grep_schedule_defs.txt:85:.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:39:.\B0544_tmp\grep_schedule_defs.txt:87:.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:42:.\B0544_tmp\grep_schedule_defs.txt:121:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_beat_entrypoints.txt:43:.\B0544_tmp\grep_schedule_defs.txt:122:.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:44:.\B0544_tmp\grep_schedule_defs.txt:123:.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:45:.\B0544_tmp\grep_schedule_defs.txt:124:.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:46:.\B0544_tmp\grep_schedule_defs.txt:125:.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:47:.\B0544_tmp\grep_schedule_defs.txt:126:.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:48:.\B0544_tmp\grep_schedule_defs.txt:127:.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:49:.\B0544_tmp\grep_schedule_defs.txt:128:.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:50:.\B0544_tmp\grep_schedule_defs.txt:129:.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:51:.\B0544_tmp\grep_schedule_defs.txt:130:.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:52:.\B0544_tmp\grep_schedule_defs.txt:131:.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:53:.\B0544_tmp\grep_schedule_defs.txt:132:.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:54:.\B0544_tmp\grep_schedule_defs.txt:133:.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:55:.\B0544_tmp\grep_schedule_defs.txt:134:.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:56:.\B0544_tmp\grep_schedule_defs.txt:135:.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:57:.\B0544_tmp\grep_schedule_defs.txt:136:.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:58:.\B0544_tmp\grep_schedule_defs.txt:137:.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:59:.\B0544_tmp\grep_schedule_defs.txt:138:.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:60:.\B0544_tmp\grep_schedule_defs.txt:139:.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:61:.\B0544_tmp\grep_schedule_defs.txt:140:.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:62:.\B0544_tmp\grep_schedule_defs.txt:141:.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:63:.\B0544_tmp\grep_schedule_defs.txt:142:.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:64:.\B0544_tmp\grep_schedule_defs.txt:143:.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:65:.\B0544_tmp\grep_schedule_defs.txt:144:.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:66:.\B0544_tmp\grep_schedule_defs.txt:145:.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:68:.\B0544_tmp\grep_schedule_defs.txt:148:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:70:.\B0544_tmp\grep_schedule_defs.txt:151:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:72:.\B0544_tmp\grep_schedule_defs.txt:154:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:74:.\B0544_tmp\grep_schedule_defs.txt:157:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:76:.\B0544_tmp\grep_schedule_defs.txt:160:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:78:.\B0544_tmp\grep_schedule_defs.txt:163:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:81:.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_tmp\grep_beat_entrypoints.txt:82:.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:84:.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:86:.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:88:.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:90:.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:92:.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:96:.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:98:.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:100:.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:102:.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:104:.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:106:.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:109:.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:111:.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:114:.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:116:.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:119:.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:130:.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:135:.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_tmp\grep_beat_entrypoints.txt:136:.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:137:.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:138:.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:139:.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:140:.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:141:.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:142:.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:143:.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:144:.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:145:.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:146:.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:147:.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:148:.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:149:.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:150:.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:151:.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:152:.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:153:.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:154:.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:155:.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:156:.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:157:.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:158:.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:159:.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:161:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:164:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:171:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:173:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:180:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_tmp\grep_beat_entrypoints.txt:182:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:34:Reasoning: The searches for cron/APScheduler/PeriodicTask/DatabaseScheduler/redbeat show only documentation and evidence artifacts, not active scheduler code. The only scheduler-like mechanism visible in code is Celery Beat via beat_schedule and celery_app.conf.beat_schedule. No competing scheduler entrypoints (cron/apscheduler) are found.
.\B0544_CONTEXT_DUMP.md:49:rg -n "beat_schedule|CELERYBEAT_SCHEDULE|CELERY_BEAT|PeriodicTask|django-celery-beat|add_periodic_task|crontab\(" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:56:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:59:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:66:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:69:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:74:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:77:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:333:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:335:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:337:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:339:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:341:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:343:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:346:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:348:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:351:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:353:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:356:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:367:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:687:rg -n "django-celery-beat|PeriodicTask|DatabaseScheduler|redbeat|celerybeat-schedule" -S --glob "!**/.git/**" --glob "!**/node_modules/**" .
.\B0544_CONTEXT_DUMP.md:693:.\B0544_tmp\cmd3.txt:1:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:694:.\B0544_tmp\cmd3.txt:3:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:695:.\B0544_tmp\cmd3.txt:5:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:696:.\B0544_tmp\cmd3.txt:7:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:697:.\B0544_tmp\cmd3.txt:9:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:698:.\B0544_tmp\cmd3.txt:11:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:699:.\B0544_tmp\cmd3.txt:14:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:700:.\B0544_tmp\cmd3.txt:16:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:701:.\B0544_tmp\cmd3.txt:19:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:702:.\B0544_tmp\cmd3.txt:21:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:703:.\B0544_tmp\cmd3.txt:24:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:704:.\B0544_tmp\cmd3.txt:35:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:705:.\B0544_tmp\cmd1.txt:2:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:706:.\B0544_tmp\cmd1.txt:5:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:707:.\B0544_tmp\cmd1.txt:12:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:708:.\B0544_tmp\cmd1.txt:15:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:709:.\B0544_tmp\cmd1.txt:20:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:710:.\B0544_tmp\cmd1.txt:23:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:711:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:712:.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:713:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:714:.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:715:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\B0544_CONTEXT_DUMP.md:716:.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\c7abcf220dc96f0029baa701341b1e6def10cbb5\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\540b1eab47622080a2d4447e674af8d7b3c6b0b6\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CONCURRENCY_SNAPSHOT.json:47:      "beat_schedule_filename": "celerybeat-schedule",
.\docs\validation\runtime\R6_context_gathering\2b0236c802b0017a50c93903c330e23d49078013\R6_CELERY_INSPECT_CONF.json:37:    "beat_schedule_filename": "celerybeat-schedule",
```

## Preliminary Conclusions

- Beat schedule exists and is loaded in celery_app; schedule keys and tasks are shown in the beat_schedule dump.
- Global beat-safe adapter task exists for tenant fan-out; refresh_all_for_tenant still requires tenant_id.
- Beat entrypoint appears only in CI harness (scripts/ci/zero_drift_v3_2.sh); Procfile/compose do not run beat.
- Competing schedulers (cron/APScheduler/database schedulers) are not present in code.
- R6 fuses are configured globally in backend/app/core/config.py and applied in backend/app/celery_app.py.

## Post-change Evidence (After Adapter + Beat Entry)

### Beat schedule dump (post-change)

Command:

```
$env:DATABASE_URL='postgresql://app_user:app_user@localhost:5432/skeldir_validation'; python -c "import sys; sys.path.append('backend'); from app.celery_app import celery_app; print(celery_app.conf.beat_schedule); print(list((celery_app.conf.beat_schedule or {}).keys()))"
```

Output:

```
{'refresh-matviews-every-5-min': {'task': 'app.tasks.matviews.pulse_matviews_global', 'schedule': 300.0, 'options': {'expires': 600}, 'kwargs': {'schedule_class': 'minute'}}, 'pii-audit-scanner': {'task': 'app.tasks.maintenance.scan_for_pii_contamination', 'schedule': <crontab: 0 4 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}, 'enforce-data-retention': {'task': 'app.tasks.maintenance.enforce_data_retention', 'schedule': <crontab: 0 3 * * * (m/h/dM/MY/d)>, 'options': {'expires': 3600}}}
['refresh-matviews-every-5-min', 'pii-audit-scanner', 'enforce-data-retention']
```

### Adapter registration (celery_app tasks)

Command:

```
$env:DATABASE_URL='postgresql://app_user:app_user@localhost:5432/skeldir_validation'; @'
import sys
sys.path.append('backend')
from app.celery_app import celery_app
celery_app.loader.import_default_modules()
print('app.tasks.matviews.pulse_matviews_global' in celery_app.tasks)
print(sorted([name for name in celery_app.tasks.keys() if name.startswith('app.tasks.matviews.')]))
'@ | python -
```

Output:

```
True
['app.tasks.matviews.pulse_matviews_global', 'app.tasks.matviews.refresh_all_for_tenant', 'app.tasks.matviews.refresh_single']
```

### Beat runtime entrypoint (Procfile)

Command:

```
Select-String -Path Procfile -Pattern "^beat:"
```

Output:

```
C:\Users\ayewhy\II SKELDIR II\Procfile:21:beat: cd backend && celery -A app.celery_app.celery_app beat --loglevel=info
```

### Local end-to-end logs (Beat + Worker)

Commands (PowerShell):

```
$env:DATABASE_URL='postgresql://app_user:app_user@localhost:5432/skeldir_validation'; $env:CELERY_BROKER_URL='sqla+postgresql://app_user:app_user@localhost:5432/skeldir_validation'; $env:CELERY_RESULT_BACKEND='db+postgresql://app_user:app_user@localhost:5432/skeldir_validation'; $env:ZG_BEAT_TEST_INTERVAL_SECONDS='2';
$worker = Start-Process -FilePath 'celery' -ArgumentList @('-A','app.celery_app.celery_app','worker','--loglevel=INFO','--pool=solo','--concurrency=1') -WorkingDirectory 'backend' -RedirectStandardOutput B0544_worker.log -RedirectStandardError B0544_worker.err -PassThru
Start-Sleep -Seconds 2
$beat = Start-Process -FilePath 'celery' -ArgumentList @('-A','app.celery_app.celery_app','beat','--loglevel=INFO','--pidfile=','--schedule=../B0544_beat_schedule','--max-interval=2') -WorkingDirectory 'backend' -RedirectStandardOutput B0544_beat.log -RedirectStandardError B0544_beat.err -PassThru
Start-Sleep -Seconds 8
Stop-Process -Id $beat.Id -Force
Stop-Process -Id $worker.Id -Force
```

Beat log excerpt (B0544_beat.err):

```
[2026-01-03 19:26:55,323: INFO/MainProcess] beat: Starting...
[2026-01-03 19:26:55,424: INFO/MainProcess] Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.matviews.pulse_matviews_global)
[2026-01-03 19:26:57,408: INFO/MainProcess] Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.matviews.pulse_matviews_global)
[2026-01-03 19:26:59,409: INFO/MainProcess] Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.matviews.pulse_matviews_global)
[2026-01-03 19:27:01,410: INFO/MainProcess] Scheduler: Sending due task refresh-matviews-every-5-min (app.tasks.matviews.pulse_matviews_global)
```

Worker log excerpt (B0544_worker.err):

```
{"level": "INFO", "logger": "app.celery_app", "message": "celery_worker_logging_configured"}
{"level": "INFO", "logger": "app.observability.worker_monitoring", "message": "celery_worker_metrics_server_started"}
{"level": "INFO", "logger": "celery.worker.consumer.connection", "message": "Connected to sqla+postgresql://app_user:**@localhost:5432/skeldir_validation"}
{"level": "INFO", "logger": "app.celery_app", "message": "celery_kombu_visibility_recovery_started"}
{"level": "INFO", "logger": "celery.apps.worker", "message": "celery@workstation ready."}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.pulse_matviews_global[384bcc0d-640a-4340-954b-076312cc161a] received"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_start", "task_id": "384bcc0d-640a-4340-954b-076312cc161a", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_dispatched", "task_id": "384bcc0d-640a-4340-954b-076312cc161a", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe"}
{"level": "INFO", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.pulse_matviews_global[384bcc0d-640a-4340-954b-076312cc161a] succeeded in 0.10899999999674037s: {'status': 'ok', 'tenant_count': 1, 'correlation_id': '8b531d0e-9ac1-4abd-b896-03002e9509fe'}"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.refresh_all_for_tenant[758c03c7-5880-43b4-ba10-c5a0a4a76b4e] received"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_event_loop_selected", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_async_entry", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_all_task_start", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "sqlalchemy.pool.impl.AsyncAdaptedQueuePool", "message": "Exception terminating connection <AdaptedConnection <asyncpg.connection.Connection object at 0x000001E85C975D50>>", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 372, in _close_connection\n    self._dialect.do_terminate(connection)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1127, in do_terminate\n    dbapi_connection.terminate()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\connectors\\asyncio.py\", line 402, in terminate\n    self.await_(asyncio.shield(self._terminate_graceful_close()))  # type: ignore[attr-defined] # noqa: E501\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 912, in _terminate_graceful_close\n    await self._connection.close(timeout=2)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 1513, in close\n    await self._protocol.close(timeout)\n  File \"asyncpg/protocol/protocol.pyx\", line 618, in close\nRuntimeError: Task <Task pending name='Task-5' coro=<AsyncAdapt_asyncpg_connection._terminate_graceful_close() running at C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py:912> cb=[shield.<locals>._inner_done_callback() at C:\\Python311\\Lib\\asyncio\\tasks.py:891]> got Future <Future pending> attached to a different loop"}
{"level": "ERROR", "logger": "asyncio", "message": "Future exception was never retrieved\nfuture: <Future finished exception=InternalClientError('got result for unknown protocol state 3')>", "exc_info": "Traceback (most recent call last):\n  File \"asyncpg/protocol/protocol.pyx\", line 892, in asyncpg.protocol.protocol.BaseProtocol._dispatch_result\nasyncpg.exceptions._base.InternalClientError: got result for unknown protocol state 3"}
{"level": "ERROR", "logger": "app.matviews.executor", "message": "matview_refresh_executor_failed", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\matviews\\executor.py\", line 105, in refresh_single_async\n    async with engine.begin() as conn:\n  File \"C:\\Python311\\Lib\\contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 1068, in begin\n    async with conn:\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\base.py\", line 121, in __aenter__\n    return await self.start(is_ctxmanager=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 275, in start\n    await greenlet_spawn(self.sync_engine.connect)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 201, in greenlet_spawn\n    result = context.throw(*sys.exc_info())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3277, in connect\n    return self._connection_cls(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 143, in __init__\n    self._dbapi_connection = engine.raw_connection()\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3301, in raw_connection\n    return self.pool.connect()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 447, in connect\n    return _ConnectionFairy._checkout(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1363, in _checkout\n    with util.safe_reraise():\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 224, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1301, in _checkout\n    result = pool._dialect._do_ping_w_event(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 728, in _do_ping_w_event\n    return self.do_ping(dbapi_connection)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1160, in do_ping\n    dbapi_connection.ping()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 818, in ping\n    self._handle_exception(error)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 799, in _handle_exception\n    raise error\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 816, in ping\n    _ = self.await_(self._async_ping())\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 825, in _async_ping\n    await tr.start()\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\transaction.py\", line 146, in start\n    await self._connection.execute(query)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 354, in execute\n    result = await self._protocol.query(query, timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"asyncpg/protocol/protocol.pyx\", line 369, in query\nRuntimeError: Task <Task pending name='Task-4' coro=<refresh_all_for_tenant_async() running at C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\matviews\\executor.py:191> cb=[_run_until_complete_cb() at C:\\Python311\\Lib\\asyncio\\base_events.py:181]> got Future <Future pending cb=[BaseProtocol._on_waiter_completed()]> attached to a different loop"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "app.tasks.matviews", "message": "matview_refresh_task_failed", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e", "correlation_id_request": "8b531d0e-9ac1-4abd-b896-03002e9509fe", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "app.celery_app", "message": "celery_task_failed", "task_name": "app.tasks.matviews.refresh_all_for_tenant", "task_id": "758c03c7-5880-43b4-ba10-c5a0a4a76b4e"}
{"level": "ERROR", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.refresh_all_for_tenant[758c03c7-5880-43b4-ba10-c5a0a4a76b4e] raised unexpected: MatviewTaskFailure('matview refresh failed: view=mv_allocation_summary outcome=FAILED')", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 479, in trace_task\n    R = retval = fun(*args, **kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 779, in __protected_call__\n    return self.run(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 152, in _wrapped\n    return task_fn(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\matviews.py\", line 261, in matview_refresh_all_for_tenant\n    return _apply_strategy(task=self, result=failed, strategy=overall)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\matviews.py\", line 164, in _apply_strategy\n    raise MatviewTaskFailure(\napp.tasks.matviews.MatviewTaskFailure: matview refresh failed: view=mv_allocation_summary outcome=FAILED"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.pulse_matviews_global[099f9c7d-57e7-4567-94ee-20e2870f0ae1] received"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_start", "task_id": "099f9c7d-57e7-4567-94ee-20e2870f0ae1", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_dispatched", "task_id": "099f9c7d-57e7-4567-94ee-20e2870f0ae1", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487"}
{"level": "INFO", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.pulse_matviews_global[099f9c7d-57e7-4567-94ee-20e2870f0ae1] succeeded in 0.10899999999674037s: {'status': 'ok', 'tenant_count': 1, 'correlation_id': '1e39dad7-75f5-4df8-b639-4a93015ba487'}"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.refresh_all_for_tenant[1a970824-7828-4c64-92b2-5d184d8d8ead] received"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_event_loop_selected", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_async_entry", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "sqlalchemy.pool.impl.AsyncAdaptedQueuePool", "message": "Exception terminating connection <AdaptedConnection <asyncpg.connection.Connection object at 0x000001E85C9987C0>>", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 372, in _close_connection\n    self._dialect.do_terminate(connection)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1127, in do_terminate\n    dbapi_connection.terminate()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\connectors\\asyncio.py\", line 402, in terminate\n    self.await_(asyncio.shield(self._terminate_graceful_close()))  # type: ignore[attr-defined] # noqa: E501\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 912, in _terminate_graceful_close\n    await self._connection.close(timeout=2)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 1513, in close\n    await self._protocol.close(timeout)\n  File \"asyncpg/protocol/protocol.pyx\", line 617, in close\n  File \"asyncpg/protocol/protocol.pyx\", line 650, in asyncpg.protocol.protocol.BaseProtocol._request_cancel\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 1682, in _cancel_current_command\n    self._cancellations.add(self._loop.create_task(self._cancel(waiter)))\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 435, in create_task\n    self._check_closed()\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 520, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed"}
{"level": "ERROR", "logger": "app.tasks.context", "message": "celery_tenant_guc_failed", "task_name": "app.tasks.matviews.refresh_all_for_tenant", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 762, in call_soon\n    self._check_closed()\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 520, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 133, in _wrapped\n    run_in_worker_loop(_set_tenant_guc_global(tenant_uuid))\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 72, in run_in_worker_loop\n    return future.result(timeout=60)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 91, in _set_tenant_guc_global\n    async with engine.begin() as conn:\n  File \"C:\\Python311\\Lib\\contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 1068, in begin\n    async with conn:\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\base.py\", line 121, in __aenter__\n    return await self.start(is_ctxmanager=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 275, in start\n    await greenlet_spawn(self.sync_engine.connect)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 201, in greenlet_spawn\n    result = context.throw(*sys.exc_info())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3277, in connect\n    return self._connection_cls(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 143, in __init__\n    self._dbapi_connection = engine.raw_connection()\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3301, in raw_connection\n    return self.pool.connect()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 447, in connect\n    return _ConnectionFairy._checkout(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1363, in _checkout\n    with util.safe_reraise():\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 224, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1301, in _checkout\n    result = pool._dialect._do_ping_w_event(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 728, in _do_ping_w_event\n    return self.do_ping(dbapi_connection)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1160, in do_ping\n    dbapi_connection.ping()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 818, in ping\n    self._handle_exception(error)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 799, in _handle_exception\n    raise error\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 816, in ping\n    _ = self.await_(self._async_ping())\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 825, in _async_ping\n    await tr.start()\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\transaction.py\", line 146, in start\n    await self._connection.execute(query)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 354, in execute\n    result = await self._protocol.query(query, timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"asyncpg/protocol/protocol.pyx\", line 369, in query\n  File \"asyncpg/protocol/protocol.pyx\", line 362, in asyncpg.protocol.protocol.BaseProtocol.query\n  File \"asyncpg/protocol/coreproto.pyx\", line 1174, in asyncpg.protocol.protocol.CoreProtocol._simple_query\n  File \"asyncpg/protocol/protocol.pyx\", line 956, in asyncpg.protocol.protocol.BaseProtocol._write\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 365, in write\n    self._loop_writing(data=bytes(data))\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 401, in _loop_writing\n    self._write_fut = self._loop._proactor.send(self._sock, data)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'send'"}
{"level": "ERROR", "logger": "app.celery_app", "message": "celery_task_failed", "task_name": "app.tasks.matviews.refresh_all_for_tenant", "task_id": "1a970824-7828-4c64-92b2-5d184d8d8ead", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.refresh_all_for_tenant[1a970824-7828-4c64-92b2-5d184d8d8ead] raised unexpected: AttributeError(\"'NoneType' object has no attribute 'send'\")", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 762, in call_soon\n    self._check_closed()\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 520, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 479, in trace_task\n    R = retval = fun(*args, **kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 779, in __protected_call__\n    return self.run(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 133, in _wrapped\n    run_in_worker_loop(_set_tenant_guc_global(tenant_uuid))\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 72, in run_in_worker_loop\n    return future.result(timeout=60)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 91, in _set_tenant_guc_global\n    async with engine.begin() as conn:\n  File \"C:\\Python311\\Lib\\contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 1068, in begin\n    async with conn:\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\base.py\", line 121, in __aenter__\n    return await self.start(is_ctxmanager=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 275, in start\n    await greenlet_spawn(self.sync_engine.connect)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 201, in greenlet_spawn\n    result = context.throw(*sys.exc_info())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3277, in connect\n    return self._connection_cls(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 143, in __init__\n    self._dbapi_connection = engine.raw_connection()\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3301, in raw_connection\n    return self.pool.connect()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 447, in connect\n    return _ConnectionFairy._checkout(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1363, in _checkout\n    with util.safe_reraise():\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 224, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1301, in _checkout\n    result = pool._dialect._do_ping_w_event(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 728, in _do_ping_w_event\n    return self.do_ping(dbapi_connection)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1160, in do_ping\n    dbapi_connection.ping()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 818, in ping\n    self._handle_exception(error)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 799, in _handle_exception\n    raise error\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 816, in ping\n    _ = self.await_(self._async_ping())\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 825, in _async_ping\n    await tr.start()\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\transaction.py\", line 146, in start\n    await self._connection.execute(query)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 354, in execute\n    result = await self._protocol.query(query, timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"asyncpg/protocol/protocol.pyx\", line 369, in query\n  File \"asyncpg/protocol/protocol.pyx\", line 362, in asyncpg.protocol.protocol.BaseProtocol.query\n  File \"asyncpg/protocol/coreproto.pyx\", line 1174, in asyncpg.protocol.protocol.CoreProtocol._simple_query\n  File \"asyncpg/protocol/protocol.pyx\", line 956, in asyncpg.protocol.protocol.BaseProtocol._write\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 365, in write\n    self._loop_writing(data=bytes(data))\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 401, in _loop_writing\n    self._write_fut = self._loop._proactor.send(self._sock, data)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'send'"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.pulse_matviews_global[fa5b8412-da56-4443-b389-2cc984841aab] received", "correlation_id_request": "1e39dad7-75f5-4df8-b639-4a93015ba487", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_start", "task_id": "fa5b8412-da56-4443-b389-2cc984841aab", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_dispatched", "task_id": "fa5b8412-da56-4443-b389-2cc984841aab", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.pulse_matviews_global[fa5b8412-da56-4443-b389-2cc984841aab] succeeded in 0.4059999999590218s: {'status': 'ok', 'tenant_count': 1, 'correlation_id': '8cf597a3-b796-4ff0-bd5f-da75a818b3dd'}", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.refresh_all_for_tenant[fca56aa8-6076-4737-8c1d-7a82279889f7] received", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_event_loop_selected", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_async_entry", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_all_task_start", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "sqlalchemy.pool.impl.AsyncAdaptedQueuePool", "message": "Exception terminating connection <AdaptedConnection <asyncpg.connection.Connection object at 0x000001E85C99B2E0>>", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 372, in _close_connection\n    self._dialect.do_terminate(connection)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1127, in do_terminate\n    dbapi_connection.terminate()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\connectors\\asyncio.py\", line 402, in terminate\n    self.await_(asyncio.shield(self._terminate_graceful_close()))  # type: ignore[attr-defined] # noqa: E501\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 912, in _terminate_graceful_close\n    await self._connection.close(timeout=2)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 1513, in close\n    await self._protocol.close(timeout)\n  File \"asyncpg/protocol/protocol.pyx\", line 618, in close\nRuntimeError: Task <Task pending name='Task-21' coro=<AsyncAdapt_asyncpg_connection._terminate_graceful_close() running at C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py:912> cb=[shield.<locals>._inner_done_callback() at C:\\Python311\\Lib\\asyncio\\tasks.py:891]> got Future <Future pending> attached to a different loop"}
{"level": "ERROR", "logger": "asyncio", "message": "Future exception was never retrieved\nfuture: <Future finished exception=InternalClientError('got result for unknown protocol state 3')>", "exc_info": "Traceback (most recent call last):\n  File \"asyncpg/protocol/protocol.pyx\", line 892, in asyncpg.protocol.protocol.BaseProtocol._dispatch_result\nasyncpg.exceptions._base.InternalClientError: got result for unknown protocol state 3"}
{"level": "ERROR", "logger": "app.matviews.executor", "message": "matview_refresh_executor_failed", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\matviews\\executor.py\", line 105, in refresh_single_async\n    async with engine.begin() as conn:\n  File \"C:\\Python311\\Lib\\contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 1068, in begin\n    async with conn:\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\base.py\", line 121, in __aenter__\n    return await self.start(is_ctxmanager=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 275, in start\n    await greenlet_spawn(self.sync_engine.connect)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 201, in greenlet_spawn\n    result = context.throw(*sys.exc_info())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3277, in connect\n    return self._connection_cls(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 143, in __init__\n    self._dbapi_connection = engine.raw_connection()\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3301, in raw_connection\n    return self.pool.connect()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 447, in connect\n    return _ConnectionFairy._checkout(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1363, in _checkout\n    with util.safe_reraise():\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 224, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1301, in _checkout\n    result = pool._dialect._do_ping_w_event(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 728, in _do_ping_w_event\n    return self.do_ping(dbapi_connection)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1160, in do_ping\n    dbapi_connection.ping()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 818, in ping\n    self._handle_exception(error)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 799, in _handle_exception\n    raise error\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 816, in ping\n    _ = self.await_(self._async_ping())\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 825, in _async_ping\n    await tr.start()\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\transaction.py\", line 146, in start\n    await self._connection.execute(query)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 354, in execute\n    result = await self._protocol.query(query, timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"asyncpg/protocol/protocol.pyx\", line 369, in query\nRuntimeError: Task <Task pending name='Task-20' coro=<refresh_all_for_tenant_async() running at C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\matviews\\executor.py:191> cb=[_run_until_complete_cb() at C:\\Python311\\Lib\\asyncio\\base_events.py:181]> got Future <Future pending cb=[BaseProtocol._on_waiter_completed()]> attached to a different loop"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.core.pg_locks", "message": "refresh_xact_lock_acquired", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "app.tasks.matviews", "message": "matview_refresh_task_failed", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_refresh_task_completed", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7", "correlation_id_request": "8cf597a3-b796-4ff0-bd5f-da75a818b3dd", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "app.celery_app", "message": "celery_task_failed", "task_name": "app.tasks.matviews.refresh_all_for_tenant", "task_id": "fca56aa8-6076-4737-8c1d-7a82279889f7"}
{"level": "ERROR", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.refresh_all_for_tenant[fca56aa8-6076-4737-8c1d-7a82279889f7] raised unexpected: MatviewTaskFailure('matview refresh failed: view=mv_allocation_summary outcome=FAILED')", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 479, in trace_task\n    R = retval = fun(*args, **kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 779, in __protected_call__\n    return self.run(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 152, in _wrapped\n    return task_fn(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\matviews.py\", line 261, in matview_refresh_all_for_tenant\n    return _apply_strategy(task=self, result=failed, strategy=overall)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\matviews.py\", line 164, in _apply_strategy\n    raise MatviewTaskFailure(\napp.tasks.matviews.MatviewTaskFailure: matview refresh failed: view=mv_allocation_summary outcome=FAILED"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.pulse_matviews_global[03196ad1-7bb2-466d-8242-eeb2b7f5d0d3] received"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_start", "task_id": "03196ad1-7bb2-466d-8242-eeb2b7f5d0d3", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87"}
{"level": "INFO", "logger": "app.tasks.matviews", "message": "matview_pulse_task_dispatched", "task_id": "03196ad1-7bb2-466d-8242-eeb2b7f5d0d3", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87"}
{"level": "INFO", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.pulse_matviews_global[03196ad1-7bb2-466d-8242-eeb2b7f5d0d3] succeeded in 0.23399999999674037s: {'status': 'ok', 'tenant_count': 1, 'correlation_id': '55d49923-467e-4f71-a4e0-601bcd263c87'}"}
{"level": "INFO", "logger": "celery.worker.strategy", "message": "Task app.tasks.matviews.refresh_all_for_tenant[33cc4dda-c858-4cd6-a709-6d62e2b7e7a9] received"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_event_loop_selected", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "INFO", "logger": "app.tasks.context", "message": "tenant_guc_async_entry", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "sqlalchemy.pool.impl.AsyncAdaptedQueuePool", "message": "Exception terminating connection <AdaptedConnection <asyncpg.connection.Connection object at 0x000001E85C99AD40>>", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 372, in _close_connection\n    self._dialect.do_terminate(connection)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1127, in do_terminate\n    dbapi_connection.terminate()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\connectors\\asyncio.py\", line 402, in terminate\n    self.await_(asyncio.shield(self._terminate_graceful_close()))  # type: ignore[attr-defined] # noqa: E501\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 912, in _terminate_graceful_close\n    await self._connection.close(timeout=2)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 1513, in close\n    await self._protocol.close(timeout)\n  File \"asyncpg/protocol/protocol.pyx\", line 617, in close\n  File \"asyncpg/protocol/protocol.pyx\", line 650, in asyncpg.protocol.protocol.BaseProtocol._request_cancel\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 1682, in _cancel_current_command\n    self._cancellations.add(self._loop.create_task(self._cancel(waiter)))\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 435, in create_task\n    self._check_closed()\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 520, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed"}
{"level": "ERROR", "logger": "app.tasks.context", "message": "celery_tenant_guc_failed", "task_name": "app.tasks.matviews.refresh_all_for_tenant", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 762, in call_soon\n    self._check_closed()\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 520, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 133, in _wrapped\n    run_in_worker_loop(_set_tenant_guc_global(tenant_uuid))\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 72, in run_in_worker_loop\n    return future.result(timeout=60)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 91, in _set_tenant_guc_global\n    async with engine.begin() as conn:\n  File \"C:\\Python311\\Lib\\contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 1068, in begin\n    async with conn:\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\base.py\", line 121, in __aenter__\n    return await self.start(is_ctxmanager=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 275, in start\n    await greenlet_spawn(self.sync_engine.connect)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 201, in greenlet_spawn\n    result = context.throw(*sys.exc_info())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3277, in connect\n    return self._connection_cls(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 143, in __init__\n    self._dbapi_connection = engine.raw_connection()\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3301, in raw_connection\n    return self.pool.connect()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 447, in connect\n    return _ConnectionFairy._checkout(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1363, in _checkout\n    with util.safe_reraise():\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 224, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1301, in _checkout\n    result = pool._dialect._do_ping_w_event(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 728, in _do_ping_w_event\n    return self.do_ping(dbapi_connection)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1160, in do_ping\n    dbapi_connection.ping()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 818, in ping\n    self._handle_exception(error)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 799, in _handle_exception\n    raise error\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 816, in ping\n    _ = self.await_(self._async_ping())\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 825, in _async_ping\n    await tr.start()\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\transaction.py\", line 146, in start\n    await self._connection.execute(query)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 354, in execute\n    result = await self._protocol.query(query, timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"asyncpg/protocol/protocol.pyx\", line 369, in query\n  File \"asyncpg/protocol/protocol.pyx\", line 362, in asyncpg.protocol.protocol.BaseProtocol.query\n  File \"asyncpg/protocol/coreproto.pyx\", line 1174, in asyncpg.protocol.protocol.CoreProtocol._simple_query\n  File \"asyncpg/protocol/protocol.pyx\", line 956, in asyncpg.protocol.protocol.BaseProtocol._write\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 365, in write\n    self._loop_writing(data=bytes(data))\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 401, in _loop_writing\n    self._write_fut = self._loop._proactor.send(self._sock, data)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'send'"}
{"level": "ERROR", "logger": "app.celery_app", "message": "celery_task_failed", "task_name": "app.tasks.matviews.refresh_all_for_tenant", "task_id": "33cc4dda-c858-4cd6-a709-6d62e2b7e7a9", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971"}
{"level": "ERROR", "logger": "celery.app.trace", "message": "Task app.tasks.matviews.refresh_all_for_tenant[33cc4dda-c858-4cd6-a709-6d62e2b7e7a9] raised unexpected: AttributeError(\"'NoneType' object has no attribute 'send'\")", "correlation_id_request": "55d49923-467e-4f71-a4e0-601bcd263c87", "tenant_id": "75060f4b-d0e2-42e7-b6de-3c3adb8fd971", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 762, in call_soon\n    self._check_closed()\n  File \"C:\\Python311\\Lib\\asyncio\\base_events.py\", line 520, in _check_closed\n    raise RuntimeError('Event loop is closed')\nRuntimeError: Event loop is closed\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 479, in trace_task\n    R = retval = fun(*args, **kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\celery\\app\\trace.py\", line 779, in __protected_call__\n    return self.run(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 133, in _wrapped\n    run_in_worker_loop(_set_tenant_guc_global(tenant_uuid))\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 72, in run_in_worker_loop\n    return future.result(timeout=60)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"C:\\Users\\ayewhy\\II SKELDIR II\\backend\\app\\tasks\\context.py\", line 91, in _set_tenant_guc_global\n    async with engine.begin() as conn:\n  File \"C:\\Python311\\Lib\\contextlib.py\", line 210, in __aenter__\n    return await anext(self.gen)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 1068, in begin\n    async with conn:\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\base.py\", line 121, in __aenter__\n    return await self.start(is_ctxmanager=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\ext\\asyncio\\engine.py\", line 275, in start\n    await greenlet_spawn(self.sync_engine.connect)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 201, in greenlet_spawn\n    result = context.throw(*sys.exc_info())\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3277, in connect\n    return self._connection_cls(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 143, in __init__\n    self._dbapi_connection = engine.raw_connection()\n                             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 3301, in raw_connection\n    return self.pool.connect()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 447, in connect\n    return _ConnectionFairy._checkout(self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1363, in _checkout\n    with util.safe_reraise():\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 224, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 1301, in _checkout\n    result = pool._dialect._do_ping_w_event(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 728, in _do_ping_w_event\n    return self.do_ping(dbapi_connection)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 1160, in do_ping\n    dbapi_connection.ping()\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 818, in ping\n    self._handle_exception(error)\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 799, in _handle_exception\n    raise error\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 816, in ping\n    _ = self.await_(self._async_ping())\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 132, in await_only\n    return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\util\\_concurrency_py3k.py\", line 196, in greenlet_spawn\n    value = await result\n            ^^^^^^^^^^^^\n  File \"C:\\Python311\\Lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\asyncpg.py\", line 825, in _async_ping\n    await tr.start()\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\transaction.py\", line 146, in start\n    await self._connection.execute(query)\n  File \"C:\\Python311\\Lib\\site-packages\\asyncpg\\connection.py\", line 354, in execute\n    result = await self._protocol.query(query, timeout)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"asyncpg/protocol/protocol.pyx\", line 369, in query\n  File \"asyncpg/protocol/protocol.pyx\", line 362, in asyncpg.protocol.protocol.BaseProtocol.query\n  File \"asyncpg/protocol/coreproto.pyx\", line 1174, in asyncpg.protocol.protocol.CoreProtocol._simple_query\n  File \"asyncpg/protocol/protocol.pyx\", line 956, in asyncpg.protocol.protocol.BaseProtocol._write\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 365, in write\n    self._loop_writing(data=bytes(data))\n  File \"C:\\Python311\\Lib\\asyncio\\proactor_events.py\", line 401, in _loop_writing\n    self._write_fut = self._loop._proactor.send(self._sock, data)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'send'"}
```

Notes:
- Worker logs show adapter receipt, matview_pulse_task_start, matview_pulse_task_dispatched, and refresh_all_for_tenant received.
- The local run surfaced asyncpg event-loop errors during matview refresh; adapter dispatch is still evidenced.
