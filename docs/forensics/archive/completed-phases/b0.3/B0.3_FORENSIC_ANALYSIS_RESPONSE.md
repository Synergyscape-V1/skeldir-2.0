# B0.3 Forensic Analysis Response
## Independent Empirical Evaluation

**Date**: 2025-11-16  
**Analyst**: Independent Forensic Analysis  
**Methodology**: Static code analysis, migration inspection, documentation review, schema comparison

---

## PART A: Engineering Analyst Billy's Questions

### A. Canonical Schema & Drift Against Architecture

#### A1.1: Canonical Source of Truth

**Question**: Today, what is the *canonical* description of the database schema: the Alembic migrations under `alembic/versions/**` or `db/schema/canonical_schema.sql` (plus docs)? If both exist, explicitly state which is authoritative for B0.3 and why.

**Answer**: 

**AUTHORITATIVE SOURCE: `db/schema/canonical_schema.sql`**

**Evidence**:
- `db/schema/canonical_schema.sql` header (lines 1-12) states: "Status: Single Source of Truth for all schema validation and migrations"
- ADR-001 (`docs/architecture/adr/ADR-001-schema-source-of-truth.md`) establishes canonical schema as source of truth
- `db/schema/CHANGE_CONTROL.md` (lines 13-14) mandates: "The canonical schema specification is the single source of truth. All schema changes must flow through the canonical spec first, then to implementation."

**Alembic migrations are IMPLEMENTATION artifacts** that must match the canonical spec. The canonical schema is the specification; migrations are the execution.

**Why**: The governance process requires updating canonical spec BEFORE creating migrations (CHANGE_CONTROL.md lines 70-187). This prevents "implementation-first" forks.

---

#### A1.2: Differences Between Canonical Schema and Alembic Migrations

**Question**: Have you observed any non-trivial differences between `canonical_schema.sql` and the Alembic migrations for the **core B0.3 tables**?

**Answer**: 

**YES - SIGNIFICANT DIFFERENCES FOUND**:

1. **`attribution_events.idempotency_key`**:
   - **Canonical** (`canonical_schema.sql:75`): `idempotency_key VARCHAR(255) NOT NULL UNIQUE` (single column)
   - **Initial Migration** (`202511131115_add_core_tables.py:106-107`): Uses `external_event_id text, correlation_id uuid` (composite approach)
   - **Later Migration** (`202511151410_realign_attribution_events.py:75-210`): Adds `idempotency_key` and drops composite indexes
   - **Status**: **INTENTIONAL** - Migration `202511151410` explicitly realigns with canonical spec (line 7: "Realign attribution_events table with canonical schema")

2. **`attribution_events.event_type`, `channel`, `processing_status`**:
   - **Canonical** (`canonical_schema.sql:79,83,107`): All present as NOT NULL
   - **Initial Migration** (`202511131115_add_core_tables.py:100-111`): **ABSENT**
   - **Later Migration** (`202511151410_realign_attribution_events.py:82-118`): Adds all columns
   - **Status**: **INTENTIONAL** - Realignment migration adds these BLOCKING columns

3. **`revenue_ledger` structure**:
   - **Canonical** (`canonical_schema.sql:239-282`): Uses `transaction_id`, `state`, `amount_cents`, `currency`, `verification_source`, `verification_timestamp`
   - **Initial Migration** (`202511131115_add_core_tables.py:239-249`): Uses `revenue_cents`, `is_verified`, `verified_at`, `reconciliation_run_id`
   - **Later Migration** (`202511151430_realign_revenue_ledger.py`): Realigns to canonical structure
   - **Status**: **INTENTIONAL** - Schema evolution documented in migration comments

4. **`revenue_state_transitions` table**:
   - **Canonical** (`canonical_schema.sql:316-332`): Present
   - **Initial Migration** (`202511131115_add_core_tables.py`): **ABSENT**
   - **Later Migration** (`202511151450_create_revenue_state_transitions.py`): Creates table
   - **Status**: **INTENTIONAL** - Created in later migration per canonical spec

**Summary**: The initial migration (`202511131115`) implemented a simplified schema. Subsequent migrations (`202511151410`, `202511151430`, `202511151450`) realign to canonical spec. This is **INTENTIONAL** - a phased implementation approach.

---

#### A1.3: Table Set Completeness

**Question**: For each table listed in the Architecture Guide's B0.3 documentation (`tenants`, `attribution_events`, `attribution_allocations`, `revenue_ledger`, `dead_events`, `revenue_state_transitions`, `reconciliation_runs`), confirm whether it exists with the same name in the migrations.

**Answer**:

| Architecture Table | Migration Status | Migration File |
|-------------------|------------------|----------------|
| `tenants` | ✅ EXISTS | `202511131115_add_core_tables.py:54-96` |
| `attribution_events` | ✅ EXISTS | `202511131115_add_core_tables.py:98-152` |
| `attribution_allocations` | ✅ EXISTS | `202511131115_add_core_tables.py:192-236` |
| `revenue_ledger` | ✅ EXISTS | `202511131115_add_core_tables.py:238-272` |
| `dead_events` | ✅ EXISTS | `202511131115_add_core_tables.py:154-190` |
| `revenue_state_transitions` | ✅ EXISTS | `202511151450_create_revenue_state_transitions.py:70-88` |
| `reconciliation_runs` | ✅ EXISTS | `202511131115_add_core_tables.py:274-308` |

**All tables exist with identical names. No renaming or merging detected.**

---

#### A1.4: Missing Columns from Architecture Guide

**Question**: For each of the above tables, identify any **columns** that the architecture guide treats as required but that are **absent** in the actual DDL.

**Answer**:

**`attribution_events`** (Initial migration vs Canonical):
- **MISSING in initial**: `idempotency_key`, `event_type`, `channel`, `campaign_id`, `conversion_value_cents`, `currency`, `event_timestamp`, `processed_at`, `processing_status`, `retry_count`
- **Status**: Added in `202511151410_realign_attribution_events.py` (realignment migration)
- **Initial migration had**: `occurred_at`, `external_event_id`, `correlation_id`, `revenue_cents` (non-canonical names/types)

**`revenue_ledger`** (Initial migration vs Canonical):
- **MISSING in initial**: `transaction_id`, `order_id`, `state`, `previous_state`, `amount_cents`, `currency`, `verification_source`, `verification_timestamp`, `metadata`
- **Initial migration had**: `revenue_cents`, `is_verified`, `verified_at`, `reconciliation_run_id` (non-canonical structure)
- **Status**: Realigned in `202511151430_realign_revenue_ledger.py`

**`dead_events`** (Initial migration vs Canonical):
- **MISSING in initial**: `event_type`, `error_type`, `error_message`, `error_traceback`, `retry_count`, `last_retry_at`, `remediation_status`, `remediation_notes`, `resolved_at`
- **Initial migration had**: `ingested_at`, `source`, `error_code`, `error_detail` (non-canonical names)
- **Status**: Enhanced in `202511151440_add_dead_events_retry_tracking.py`

**Summary**: Initial migration implemented simplified schema. Realignment migrations add canonical columns. **All gaps are documented and remediated in later migrations.**

---

### B. Idempotency Design & Ingestion Coupling

#### B2.1: `idempotency_key` Column Existence

**Question**: Confirm whether **any** `idempotency_key` column exists in `attribution_events` or any related table.

**Answer**: 

**YES - `idempotency_key` EXISTS in `attribution_events`**

**Evidence**:
- **Canonical Schema** (`canonical_schema.sql:75`): `idempotency_key VARCHAR(255) NOT NULL UNIQUE`
- **Migration** (`202511151410_realign_attribution_events.py:75-78`): Adds `idempotency_key VARCHAR(255)`
- **Migration** (`202511151410_realign_attribution_events.py:168-170`): Sets NOT NULL
- **Migration** (`202511151410_realign_attribution_events.py:207-210`): Creates UNIQUE index `idx_events_idempotency`

**Initial migration** (`202511131115_add_core_tables.py`) used composite approach (`external_event_id` + `correlation_id`), but this was replaced by canonical `idempotency_key` in realignment migration.

---

#### B2.2: Idempotency Mechanism Confirmation

**Question**: The migrations implement idempotency via partial unique indexes on `(tenant_id, external_event_id)` and `(tenant_id, correlation_id)`. Confirm whether these two unique indexes are intended to be the **only** idempotency mechanism at the database level.

**Answer**: 

**NO - These indexes are OBSOLETE**

**Evidence**:
- **Initial Migration** (`202511131115_add_core_tables.py:121-131`): Creates composite indexes
- **Realignment Migration** (`202511151410_realign_attribution_events.py:228-234`): **DROPS** these composite indexes
- **Realignment Migration** (`202511151410_realign_attribution_events.py:207-210`): Creates single-column UNIQUE index on `idempotency_key`

**Current State**: The **ONLY** idempotency mechanism is the UNIQUE constraint on `idempotency_key` (via `idx_events_idempotency`). The composite indexes were removed during realignment.

---

#### B2.3: NULL Constraint on Idempotency Fields

**Question**: In the current DDL, is there any constraint preventing both `external_event_id` and `correlation_id` from being `NULL` simultaneously?

**Answer**: 

**NO CONSTRAINT EXISTS - Both can be NULL simultaneously**

**Evidence**:
- **Current Schema** (after realignment): `external_event_id` and `correlation_id` are **nullable TEXT/UUID columns** with **NO NOT NULL constraints**
- **Initial Migration** (`202511131115_add_core_tables.py:106-107`): Both defined as nullable
- **Realignment Migration** (`202511151410_realign_attribution_events.py`): Does NOT add NOT NULL constraints to these columns
- **Idempotency is now enforced via `idempotency_key`** (NOT NULL, UNIQUE)

**However**: Since `idempotency_key` is NOT NULL and UNIQUE, rows cannot be inserted without an idempotency key. The `external_event_id`/`correlation_id` fields are now **legacy/informational only** and can both be NULL.

**Conclusion**: **Rows CAN be inserted with both `external_event_id` and `correlation_id` NULL**, but they MUST have a non-NULL `idempotency_key` (enforced by NOT NULL constraint).

---

#### B2.4: CHECK Constraints on Idempotency Fields

**Question**: Are there any CHECK constraints or NOT NULL constraints on `external_event_id` or `correlation_id` that narrow the valid combinations?

**Answer**: 

**NO CHECK constraints exist on `external_event_id` or `correlation_id`**

**Evidence**:
- **Initial Migration** (`202511131115_add_core_tables.py:106-107`): No constraints beyond nullable
- **Realignment Migration** (`202511151410_realign_attribution_events.py`): No constraints added to these columns
- **Partial Indexes** (now dropped) had WHERE clauses, but no CHECK constraints

**Current State**: `external_event_id` and `correlation_id` are **unconstrained nullable columns** (informational only, not used for idempotency).

---

#### B2.5: Documented Expectation for Idempotency Fields

**Question**: For B0.4 ingestion, is there any documented expectation that **exactly one** of `external_event_id` or `correlation_id` will be present per ingested event?

**Answer**: 

**NO EXPLICIT DOCUMENTED INVARIANT FOUND**

**Evidence**:
- **Migration Comments** (`202511131115_add_core_tables.py:150-152`): Describes `correlation_id` as "Correlation ID from X-Correlation-ID header" but does NOT state mutual exclusivity
- **Canonical Schema** (`canonical_schema.sql`): Does NOT mention `external_event_id` or `correlation_id` (uses `idempotency_key` only)
- **Realignment Migration** (`202511151410_realign_attribution_events.py:129-138`): Backfills `idempotency_key` from either field but does NOT document mutual exclusivity rule

**Conclusion**: **No explicit invariant documented**. The realignment migration suggests both fields can coexist (backfill uses COALESCE), but there is no documented rule requiring exactly one to be present.

---

#### B2.6: Contract Alignment - Idempotency Key Divergence

**Question**: The architecture guide models idempotency via a single `idempotency_key` string, while the migrations use `external_event_id`/`correlation_id`. Is there *any* mapping or explanation in `db/schema/CHANGE_CONTROL.md` or related docs that describes this divergence as a deliberate evolution?

**Answer**: 

**NO DOCUMENTED EXPLANATION OF DIVERGENCE FOUND**

**Evidence**:
- **CHANGE_CONTROL.md**: Does NOT mention idempotency key evolution
- **Realignment Migration** (`202511151410_realign_attribution_events.py:7-10`): States "replaces composite approach" but does NOT explain WHY
- **Canonical Schema** (`canonical_schema.sql:74-75`): Comment says "Single-column idempotency key (replaces composite external_event_id/correlation_id)" but does NOT document rationale

**Conclusion**: **The divergence is UNDOCUMENTED**. The realignment migration implements canonical spec but does NOT explain the architectural decision to move from composite to single-column approach.

---

### C. RLS Enforcement & Tenant Isolation

#### C3.1: RLS Coverage - Tables with RLS Enabled

**Question**: List the exact set of tables that currently have `ENABLE ROW LEVEL SECURITY` and the `tenant_isolation_policy` applied.

**Answer**: 

**Tables with RLS Enabled** (from `202511131120_add_rls_policies.py:39-45`):

1. `attribution_events` ✅
2. `dead_events` ✅
3. `attribution_allocations` ✅
4. `revenue_ledger` ✅
5. `reconciliation_runs` ✅

**RLS Implementation** (`202511131120_add_rls_policies.py:67-71`):
```sql
CREATE POLICY tenant_isolation_policy ON {table_name}
    USING (tenant_id = current_setting('app.current_tenant_id')::uuid)
    WITH CHECK (tenant_id = current_setting('app.current_tenant_id')::uuid)
```

**Matches Architecture Expectation**: ✅ YES - All 5 tenant-scoped tables have RLS enabled.

**Note**: `tenants` table itself is NOT in the list (line 38: "excluding tenants table itself"). This is intentional - tenants table has its own RLS policy defined in canonical schema.

---

#### C3.2: Missing RLS on Tenant-Scoped Tables

**Question**: Are there any tables that **should** be tenant-scoped according to the architecture that currently do *not* have RLS applied?

**Answer**: 

**POTENTIALLY MISSING: `revenue_state_transitions`**

**Evidence**:
- **Canonical Schema** (`canonical_schema.sql:316-332`): `revenue_state_transitions` table exists but **NO RLS policy defined**
- **Migration** (`202511151450_create_revenue_state_transitions.py:70-88`): Creates table but **NO RLS ENABLE or POLICY creation**
- **Table has `ledger_id` FK** but **NO `tenant_id` column** - RLS cannot be applied without tenant_id

**Architecture Expectation**: `revenue_state_transitions` is linked to `revenue_ledger` (which has `tenant_id`), but the transitions table itself does NOT have `tenant_id` and therefore cannot have RLS.

**Conclusion**: **`revenue_state_transitions` is NOT tenant-scoped at the table level**. Access control relies on FK relationship to `revenue_ledger` (which has RLS). This may be **INTENTIONAL** (audit table accessed via ledger) or **UNINTENTIONAL** (should have tenant_id for direct queries).

**Other Tables**: All other B0.3 tables have RLS. `pii_audit_findings` (from `202511161210_add_pii_audit_table.py`) does NOT have RLS, but this is an operations/audit table, not a tenant-scoped analytics table.

---

#### C3.3: Application Code Setting Tenant Context

**Question**: Confirm whether you have found **any** production-intended code path that calls `set_config('app.current_tenant_id', tenant_id::text, …)` in the codebase.

**Answer**: 

**NO APPLICATION CODE FOUND**

**Evidence**:
- **Grep Search** (`grep -r "set_config\|current_setting" backend/`): **ZERO matches**
- **Codebase Search**: No FastAPI middleware, dependency, or database session code that sets `app.current_tenant_id`
- **Documentation** (`202511131120_add_rls_policies.py:22-24`): States "Application must set tenant context via: set_config('app.current_tenant_id', tenant_id::text, false)" but this is **documentation only, not implementation**

**Conclusion**: **The RLS policy currently has NO mechanism wired from the app layer**. The policy exists in the database, but there is no application code that sets the tenant context. **This is a CRITICAL GAP** - RLS will block ALL queries (default-deny) until application code is implemented.

**Expected Pattern** (from `docs/forensics/archive/implementation-phases/b0.3/B0.3_FORENSIC_CONTEXT_ANALYSIS_COMPLETE.md:2989-3003`): FastAPI dependency should call `SET LOCAL app.current_tenant_id = '{tenant_id}'`, but this code does NOT exist in `backend/`.

---

#### C3.4: RLS Test Coverage

**Question**: In `db/tests/test_rls_isolation.sql`, which operations are actually covered (SELECT, INSERT, UPDATE, DELETE) and on which tables?

**Answer**: 

**Test Coverage** (from `db/tests/test_rls_isolation.sql`):

**Operations Covered**:
1. **SELECT** - Test 1 (lines 33-43): Cross-tenant SELECT denial
2. **INSERT** - Test 2 (lines 52-69): Cross-tenant INSERT denial
3. **UPDATE** - Test 3 (lines 76-94): Cross-tenant UPDATE denial
4. **DELETE** - Test 4 (lines 101-117): Cross-tenant DELETE denial
5. **GUC Validation** - Tests 5-6 (lines 124-153): Unset/NULL GUC = no access
6. **Valid Access** - Test 7 (lines 160-172): Tenant A can access Tenant A data
7. **Multi-Table** - Test 8 (lines 179-219): Tests `dead_events`, `attribution_allocations`, `revenue_ledger`, `reconciliation_runs`

**Tables Tested**:
- `attribution_events` ✅ (primary test table)
- `dead_events` ✅ (Test 8)
- `attribution_allocations` ✅ (Test 8)
- `revenue_ledger` ✅ (Test 8)
- `reconciliation_runs` ✅ (Test 8)

**Coverage Limitations**:
- **NO JOIN queries tested** - Only single-table operations
- **NO materialized view queries tested** - RLS interaction with matviews not validated
- **NO aggregate queries tested** - COUNT, SUM, etc. not validated with RLS

**Conclusion**: **Comprehensive single-table coverage, but NO complex query patterns tested** (joins, matviews, aggregates).

---

#### C3.5: Materialized View Tenant Isolation

**Question**: For each materialized view (`mv_realtime_revenue`, `mv_reconciliation_status`, `mv_channel_performance`, `mv_daily_revenue_summary`), confirm whether it is defined in a way that guarantees tenant isolation.

**Answer**: 

**Materialized View Analysis**:

1. **`mv_realtime_revenue`** (`202511131119_add_materialized_views.py:45-54`):
   - **Query**: `GROUP BY rl.tenant_id` ✅
   - **Source**: `revenue_ledger` (has RLS)
   - **Tenant Isolation**: ✅ **GUARANTEED** - Groups by tenant_id, source table has RLS

2. **`mv_reconciliation_status`** (`202511131119_add_materialized_views.py:67-81`):
   - **Query**: `GROUP BY tenant_id` (implicit in JOIN) ✅
   - **Source**: `reconciliation_runs` (has RLS)
   - **Tenant Isolation**: ✅ **GUARANTEED** - Groups by tenant_id, source table has RLS

3. **`mv_channel_performance`** (`202511151500_add_mv_channel_performance.py:70-83`):
   - **Query**: `GROUP BY tenant_id, channel_code, DATE_TRUNC('day', created_at)` ✅
   - **Source**: `attribution_allocations` (has RLS)
   - **Tenant Isolation**: ✅ **GUARANTEED** - Groups by tenant_id, source table has RLS

4. **`mv_daily_revenue_summary`** (`202511151510_add_mv_daily_revenue_summary.py:74-86`):
   - **Query**: `GROUP BY tenant_id, DATE_TRUNC('day', verification_timestamp), state, currency` ✅
   - **Source**: `revenue_ledger` (has RLS)
   - **Tenant Isolation**: ✅ **GUARANTEED** - Groups by tenant_id, source table has RLS

**Conclusion**: **ALL materialized views guarantee tenant isolation** via GROUP BY tenant_id and source tables with RLS.

**Note**: Materialized views themselves do NOT have RLS policies (PostgreSQL does not support RLS on matviews). Access control relies on:
1. Source table RLS (filters data during REFRESH)
2. Application-level filtering (WHERE tenant_id = ... in queries)

---

#### C3.6: RLS-Materialized View Interaction Documentation

**Question**: Are there any comments or docs clarifying how RLS interacts with these materialized views?

**Answer**: 

**LIMITED DOCUMENTATION FOUND**

**Evidence**:
- **Migration Comments** (`202511131119_add_materialized_views.py:16-19`): States "Refresh policy: CONCURRENTLY with TTL-based refresh (30-60s)" but does NOT explain RLS interaction
- **Materialized View Comments**: Do NOT mention RLS
- **Architecture Docs** (`docs/database/object-catalog.md:322`): States "Refresh Policy: CONCURRENTLY with TTL-based refresh (30-60s)" but does NOT explain RLS

**Conclusion**: **The absence of RLS-materialized view interaction documentation is CONFIRMED**. No docs explain:
- How RLS filters data during REFRESH
- Whether application must filter by tenant_id when querying matviews
- Whether matviews should have application-level tenant filtering

---

### D. Index Strategy & OLAP Readiness

#### D4.1: Index-Query Mapping

**Question**: For each composite index you've defined, specify which **concrete query pattern(s)** they are intended to support.

**Answer**: 

**Composite Indexes and Query Patterns**:

1. **`idx_attribution_events_tenant_occurred_at`** (`202511131115_add_core_tables.py:134-136`):
   - **Index**: `(tenant_id, occurred_at DESC)`
   - **Query Pattern**: Time-series event retrieval by tenant
   - **Intended Use**: **NOT DOCUMENTED** - No endpoint/module reference found
   - **Later Migration** (`202511151410_realign_attribution_events.py:241-243`): Replaced by `idx_events_tenant_timestamp` on `(tenant_id, event_timestamp DESC)`

2. **`idx_attribution_allocations_tenant_created_at`** (`202511131115_add_core_tables.py:214-216`):
   - **Index**: `(tenant_id, created_at DESC)`
   - **Query Pattern**: Recent allocations by tenant
   - **Intended Use**: **NOT DOCUMENTED** - No endpoint/module reference found

3. **`idx_revenue_ledger_tenant_updated_at`** (`202511131115_add_core_tables.py:259-261`):
   - **Index**: `(tenant_id, updated_at DESC)`
   - **Query Pattern**: Recent revenue updates by tenant
   - **Intended Use**: **NOT DOCUMENTED** - No endpoint/module reference found

4. **`idx_events_processing_status`** (`202511151410_realign_attribution_events.py:246-249`):
   - **Index**: `(processing_status, processed_at) WHERE processing_status = 'pending'`
   - **Query Pattern**: Worker queue queries for pending events
   - **Intended Use**: **DOCUMENTED** - Comment (line 317-319) states "Enable fast worker queue queries. Required for: B0.5 worker queue."

5. **`idx_allocations_channel_performance`** (from canonical schema, line 217-219):
   - **Index**: `(tenant_id, channel, created_at DESC) INCLUDE (allocated_revenue_cents, confidence_score)`
   - **Query Pattern**: Channel performance dashboards
   - **Intended Use**: **NOT FOUND IN MIGRATIONS** - This index is in canonical schema but NOT in actual migrations

**Conclusion**: **Most indexes lack documented query pattern mappings**. Only `idx_events_processing_status` has explicit documentation linking it to B0.5 worker queue.

---

#### D4.2: Missing `idx_events_processing_status` Index

**Question**: The architecture guide suggests indexes like `idx_events_processing_status` for pending background work. Confirm whether such an index actually exists in the migrations.

**Answer**: 

**YES - `idx_events_processing_status` EXISTS**

**Evidence**:
- **Canonical Schema** (`canonical_schema.sql:125-127`): Defines `idx_events_processing_status` on `(processing_status, processed_at) WHERE processing_status = 'pending'`
- **Migration** (`202511151410_realign_attribution_events.py:246-249`): Creates index with exact same definition
- **Comment** (line 317-319): Documents purpose as "Enable fast worker queue queries. Required for: B0.5 worker queue."

**Conclusion**: **Index EXISTS and matches architecture guide specification.**

---

#### D4.3: JSONB Query Patterns and GIN Indexes

**Question**: Are there any known or planned queries that filter on or join by fields inside `attribution_events.raw_payload` or `dead_events.error_detail/raw_payload`?

**Answer**: 

**NO DOCUMENTED QUERY PATTERNS FOUND**

**Evidence**:
- **Grep Search**: No queries filtering on `raw_payload->>'channel'` or similar JSONB paths
- **Migration Comments**: Do NOT document JSONB query patterns
- **Canonical Schema**: Does NOT mention JSONB indexing requirements

**GIN Index Status**:
- **`attribution_events.raw_payload`**: **NO GIN INDEX** (confirmed by grep search - no GIN index creation in migrations)
- **`dead_events.raw_payload`**: **NO GIN INDEX** (confirmed)
- **`dead_events.error_detail`**: **NO GIN INDEX** (confirmed - column is JSONB but no index)

**Conclusion**: **NO GIN indexes exist on JSONB columns, and NO documented query patterns require them.** This suggests JSONB is used for storage only, not querying.

---

#### D4.4: GIN Index Absence Documentation

**Question**: Is the absence of GIN indexes on JSONB documented anywhere as an explicit "defer until we see real workloads" decision?

**Answer**: 

**NO DOCUMENTATION FOUND**

**Evidence**:
- **Migration Comments**: Do NOT mention GIN indexes or JSONB indexing strategy
- **Canonical Schema**: Does NOT mention GIN indexes
- **Architecture Docs**: Do NOT document JSONB indexing decisions

**Conclusion**: **The absence of GIN indexes is NOT documented as an explicit decision.** It is simply not addressed in any documentation.

---

### E. Data Integrity, Ledger, and Auditability

#### E5.1: Revenue State Transitions DDL and Triggers

**Question**: Confirm the current DDL for `revenue_state_transitions` and whether there is **any** trigger that automatically writes to `revenue_state_transitions` when ledger state changes.

**Answer**: 

**DDL for `revenue_state_transitions`** (`202511151450_create_revenue_state_transitions.py:70-88`):

```sql
CREATE TABLE revenue_state_transitions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    ledger_id UUID NOT NULL REFERENCES revenue_ledger(id) ON DELETE CASCADE,
    from_state VARCHAR(50),
    to_state VARCHAR(50) NOT NULL,
    reason TEXT,
    transitioned_at TIMESTAMPTZ NOT NULL DEFAULT now()
)
```

**Trigger Status**: **NO TRIGGER EXISTS**

**Evidence**:
- **Migration** (`202511151450_create_revenue_state_transitions.py`): Creates table only, **NO TRIGGER creation**
- **Grep Search**: No trigger functions or CREATE TRIGGER statements for `revenue_state_transitions`
- **Canonical Schema** (`canonical_schema.sql:316-332`): Defines table but **NO TRIGGER specification**

**Conclusion**: **No such trigger exists.** The table is created but has no automatic population mechanism. State transitions must be written **manually by application code**.

---

#### E5.2: `is_verified` and `verified_at` Fields

**Question**: The backend answer mentions `is_verified` and `verified_at` fields on `revenue_ledger`. Are these fields present in the architecture guide's table definition?

**Answer**: 

**NO - These fields are NOT in canonical schema**

**Evidence**:
- **Canonical Schema** (`canonical_schema.sql:239-282`): `revenue_ledger` uses `verification_source` and `verification_timestamp`, **NOT** `is_verified`/`verified_at`
- **Initial Migration** (`202511131115_add_core_tables.py:245-247`): Uses `is_verified boolean`, `verified_at timestamptz`
- **Realignment Migration** (`202511151430_realign_revenue_ledger.py`): Replaces with canonical `verification_source` and `verification_timestamp`

**Conclusion**: **`is_verified` and `verified_at` are implementation-specific extensions that were REMOVED during realignment.** The canonical schema uses `verification_source` and `verification_timestamp` instead. **This divergence is NOT documented** - the realignment migration does not explain why the fields changed.

---

#### E5.3: Dead Events Constraints

**Question**: For `dead_events`, do we have **any** constraints tying `correlation_id` / `external_event_id` back to `attribution_events`?

**Answer**: 

**NO FOREIGN KEY CONSTRAINTS EXIST**

**Evidence**:
- **Initial Migration** (`202511131115_add_core_tables.py:154-167`): `dead_events` has `correlation_id uuid` and `external_event_id text` but **NO FK constraints**
- **Canonical Schema** (`canonical_schema.sql:343-377`): Does NOT define FK constraints on these fields
- **Migration Comments** (`202511131115_add_core_tables.py:188-190`): Describes `correlation_id` as "Links dead_events, attribution_events" but this is **informational only, not enforced**

**Conclusion**: **These are purely informational fields with NO database-level constraints.** Linkage is **soft** (application-level correlation) not **hard** (FK constraint).

---

#### E5.4: CHECK Constraints on Dead Events Fields

**Question**: Are there any CHECK constraints on `remediation_status`, `error_code`, or related fields?

**Answer**: 

**YES - CHECK constraint on `remediation_status`**

**Evidence**:
- **Migration** (`202511151440_add_dead_events_retry_tracking.py:161-165`): Creates constraint `ck_dead_events_remediation_status_valid` with values `('pending', 'in_progress', 'resolved', 'ignored')`
- **Canonical Schema** (`canonical_schema.sql:391-392`): Defines constraint with values `('pending', 'in_progress', 'resolved', 'abandoned')`

**MISMATCH DETECTED**:
- **Migration**: Uses `'ignored'`
- **Canonical**: Uses `'abandoned'`

**Other Fields**:
- **`error_code`**: **NO CHECK constraint** (initial migration has `error_code text NOT NULL` but no enum constraint)
- **`error_type`**: **NO CHECK constraint** (added in `202511151440`, defined as `VARCHAR(100) NOT NULL` but no enum)

**Conclusion**: **Only `remediation_status` has CHECK constraint, but there is a MISMATCH between migration and canonical schema** (`'ignored'` vs `'abandoned'`).

---

### F. Privacy-First Enforcement at the Schema Layer

#### F6.1: PII Presence in Analytics Tables

**Question**: Aside from administrative fields on `tenants`, confirm that **none** of the analytics tables contain columns that directly store PII.

**Answer**: 

**NO PII COLUMNS DETECTED IN ANALYTICS TABLES**

**Table-by-Table Analysis**:

1. **`attribution_events`** (`canonical_schema.sql:61-119`):
   - Columns: `id`, `tenant_id`, `session_id`, `idempotency_key`, `event_type`, `channel`, `campaign_id`, `conversion_value_cents`, `currency`, `event_timestamp`, `processed_at`, `processing_status`, `retry_count`, `raw_payload`, `created_at`, `updated_at`
   - **NO PII columns** ✅

2. **`attribution_allocations`** (`canonical_schema.sql:158-208`):
   - Columns: `id`, `tenant_id`, `event_id`, `model_type`, `model_version`, `channel`, `allocated_revenue_cents`, `confidence_score`, `credible_interval_lower_cents`, `credible_interval_upper_cents`, `convergence_r_hat`, `effective_sample_size`, `verified`, `verification_source`, `verification_timestamp`, `created_at`, `updated_at`
   - **NO PII columns** ✅

3. **`revenue_ledger`** (`canonical_schema.sql:239-282`):
   - Columns: `id`, `tenant_id`, `transaction_id`, `order_id`, `state`, `previous_state`, `amount_cents`, `currency`, `verification_source`, `verification_timestamp`, `metadata`, `created_at`, `updated_at`
   - **NO PII columns** ✅ (metadata is JSONB but should not contain PII per comments)

4. **`dead_events`** (`canonical_schema.sql:343-377`):
   - Columns: `id`, `tenant_id`, `event_type`, `raw_payload`, `error_type`, `error_message`, `error_traceback`, `retry_count`, `last_retry_at`, `remediation_status`, `remediation_notes`, `created_at`, `resolved_at`
   - **NO PII columns** ✅ (raw_payload should have PII stripped per comments)

**Conclusion**: **All analytics tables are PII-free at the column level.** PII may exist in JSONB columns (`raw_payload`, `metadata`) but should be stripped before persistence per migration comments.

---

#### F6.2: DB-Level PII Enforcement

**Question**: Are there **any** DB-level CHECK constraints or triggers that inspect `raw_payload` or other JSONB columns for known PII keys/regex patterns?

**Answer**: 

**YES - PII Guardrail Triggers Exist**

**Evidence**:
- **Migration** (`202511161200_add_pii_guardrail_triggers.py`): Creates triggers `trg_events_pii_guardrail` and `trg_dead_events_pii_guardrail`
- **Trigger Function** (`202511161200_add_pii_guardrail_triggers.py:77-115`): `fn_detect_pii_keys()` scans JSONB for PII keys (`email`, `phone`, `ssn`, `ip_address`, `first_name`, `last_name`, `address`)
- **Trigger Behavior**: **RAISES EXCEPTION** if PII keys detected (prevents INSERT/UPDATE)

**Conclusion**: **PII enforcement is HYBRID**:
- **Layer 1**: Application layer (should strip PII before persistence)
- **Layer 2**: Database triggers (block PII key presence in JSONB)
- **Layer 3**: Audit scanning (`fn_scan_pii_contamination()` from `202511161210_add_pii_audit_table.py`)

**PII enforcement is NOT purely at application layer** - database triggers provide defense-in-depth.

---

#### F6.3: PII Audit Table Summary

**Question**: For the PII audit table created in `202511161210_add_pii_audit_table.py`, summarize its columns and intended use.

**Answer**: 

**PII Audit Table: `pii_audit_findings`**

**Columns** (`202511161210_add_pii_audit_table.py:64-74`):
1. `id` - BIGSERIAL PRIMARY KEY
2. `table_name` - TEXT NOT NULL (source table: attribution_events, dead_events, revenue_ledger)
3. `column_name` - TEXT NOT NULL (raw_payload or metadata)
4. `record_id` - UUID NOT NULL (contaminated record ID)
5. `detected_key` - TEXT NOT NULL (PII key name: email, phone, ssn, etc.)
6. `sample_snippet` - TEXT (redacted snippet, optional)
7. `detected_at` - TIMESTAMPTZ NOT NULL DEFAULT NOW()

**Intended Use** (`202511161210_add_pii_audit_table.py:8-13`):
- **Layer 3 (Operations Audit & Monitoring)** of PII Defense-in-Depth strategy
- Detects residual PII contamination if Layer 1 (app) or Layer 2 (triggers) fail
- Provides operational visibility into PII risk
- Enables compliance auditing and incident response

**Trigger Wiring**: **NO TRIGGER WIRES THIS TABLE INTO NORMAL FLOWS**

**Evidence**:
- **Migration** (`202511161210_add_pii_audit_table.py:139-261`): Creates function `fn_scan_pii_contamination()` that **manually scans** and inserts findings
- **Function is BATCH OPERATION** - intended for periodic scheduled execution, not per-transaction
- **NO automatic trigger** populates this table during normal INSERT/UPDATE operations

**Conclusion**: **Table is standalone with NO active trigger usage.** It is populated by **manual/scheduled execution** of `fn_scan_pii_contamination()`, not by automatic triggers.

---

### G. Migration Infrastructure, CI Enforcement, and Change Control

#### G7.1: CI Workflow Invocation of `validate-migration.sh`

**Question**: Confirm whether `scripts/validate-migration.sh` is actually invoked in any CI workflow.

**Answer**: 

**NO CI WORKFLOW INVOCATION FOUND**

**Evidence**:
- **Script Exists**: `scripts/validate-migration.sh` (lines 1-112) - Detects destructive DDL patterns
- **GitHub Workflows**: **NO `.github/workflows/` directory found** (glob search returned 0 files)
- **CI Configuration**: No GitHub Actions, GitLab CI, or other CI config files found

**Conclusion**: **The script is PRESENT but UNUSED in CI.** There is no CI workflow that invokes this validation script.

---

#### G7.2: `# CI:DESTRUCTIVE_OK` Bypass Comments

**Question**: Are there **any existing migrations** that contain the `# CI:DESTRUCTIVE_OK` bypass comment?

**Answer**: 

**NO BYPASS COMMENTS FOUND**

**Evidence**:
- **Grep Search** (`grep -r "CI:DESTRUCTIVE_OK" alembic/`): **ZERO matches**
- **Script** (`scripts/validate-migration.sh:76`): Checks for bypass comments but none exist

**Conclusion**: **No migrations contain the bypass comment.** All migrations either pass validation (no destructive patterns) or would fail validation if the script were run.

---

#### G7.3: Downgrade Function Behavior

**Question**: For the core B0.3 migrations, are the `downgrade()` functions purely mechanical reversals or do any attempt to preserve or transform data?

**Answer**: 

**ALL DOWNGRADE FUNCTIONS ARE MECHANICAL REVERSALS**

**Evidence**:

1. **`202511131115_add_core_tables.py:311-331`**:
   - **Behavior**: Drops all 6 tables via `DROP TABLE IF EXISTS ... CASCADE`
   - **Data Preservation**: **NO** - All data is lost

2. **`202511131119_add_materialized_views.py:94-102`**:
   - **Behavior**: Drops materialized views via `DROP MATERIALIZED VIEW IF EXISTS ... CASCADE`
   - **Data Preservation**: **NO** - Matview data is lost (but base table data preserved)

3. **`202511131120_add_rls_policies.py:80-93`**:
   - **Behavior**: Drops RLS policies and disables RLS
   - **Data Preservation**: **YES** - Table data preserved, only security policies removed

4. **`202511151410_realign_attribution_events.py:322-365`**:
   - **Behavior**: Drops canonical columns, restores old composite indexes
   - **Data Preservation**: **NO** - Column data is lost

5. **`202511151450_create_revenue_state_transitions.py:136-143`**:
   - **Behavior**: Drops table via `DROP TABLE IF EXISTS ... CASCADE`
   - **Data Preservation**: **NO** - All audit data is lost

**Conclusion**: **All downgrade functions are mechanical reversals with NO data preservation or transformation.** Downgrades will cause **DATA LOSS** for schema changes (column drops, table drops).

---

#### G7.4: Downgrade Policy Documentation

**Question**: Is there any written guidance in `db/schema/CHANGE_CONTROL.md` that limits when downgrades can be safely used in non-dev environments?

**Answer**: 

**NO DOWNGRADE POLICY DOCUMENTED**

**Evidence**:
- **CHANGE_CONTROL.md**: Does NOT mention downgrade safety or limitations
- **Migration Comments**: Some migrations have WARNING comments (e.g., `202511151450_create_revenue_state_transitions.py:140`: "WARNING: This will drop the table and all audit data in it") but no policy

**Conclusion**: **Policy is NOT documented.** There is no guidance on when downgrades are safe vs. unsafe in staging/production environments.

---

### H. Data Retention & Storage Limitation

#### H8.1: Retention Enforcement Mechanism

**Question**: Architecture mandates 90-day automatic deletion. Confirm whether **any** retention-related mechanism is present at the schema or migration level.

**Answer**: 

**NO RETENTION ENFORCEMENT MECHANISM FOUND**

**Evidence**:
- **Grep Search** (`grep -ri "expires_at\|retention\|90.*day\|storage.*limitation" alembic/`): **NO retention columns or mechanisms found**
- **Migrations**: No `expires_at` columns, no scheduled deletion SQL, no retention triggers
- **Canonical Schema**: Does NOT define retention columns or mechanisms
- **Materialized Views**: `mv_channel_performance` has 90-day rolling window (`WHERE created_at >= CURRENT_DATE - INTERVAL '90 days'`) but this is **query filtering, not data deletion**

**Conclusion**: **B0.3 currently has NO retention enforcement.** The 90-day requirement is architecturally mandated but **NOT implemented** at the schema level.

---

#### H8.2: Retention Implementation Intent Documentation

**Question**: Are there any references that describe where retention is *intended* to be implemented?

**Answer**: 

**NO RETENTION IMPLEMENTATION INTENT DOCUMENTED**

**Evidence**:
- **Migration Comments**: Do NOT mention retention implementation strategy
- **Canonical Schema**: Does NOT document retention approach
- **Architecture Docs**: Do NOT specify DB vs. background tasks vs. external scheduler

**Conclusion**: **Retention is currently UNSPECIFIED in implementation artifacts.** No documentation describes whether retention should be:
- Database-level (scheduled SQL jobs)
- Application-level (background tasks)
- External scheduler (cron, Kubernetes jobs)

---

### I. Schema–Contract Integration (B0.1 → B0.3)

#### I9.1: Revenue Field Type and Unit Alignment

**Question**: For all revenue-related fields, confirm whether the OpenAPI contracts express these values as **integers in cents** or as decimals in currency units.

**Answer**: 

**CONTRACTS USE FLOAT (DOLLARS), SCHEMA USES INTEGER (CENTS)**

**Evidence**:

1. **OpenAPI Contract** (`api-contracts/openapi/v1/attribution.yaml:47-50`):
   ```yaml
   total_revenue:
     type: number
     format: float
     description: Total revenue in dollars
     example: 125000.50
   ```

2. **Database Schema** (`canonical_schema.sql:91`):
   ```sql
   conversion_value_cents INTEGER
   ```

3. **Materialized View** (`202511131119_add_materialized_views.py:49`):
   ```sql
   COALESCE(SUM(rl.revenue_cents), 0) / 100.0 AS total_revenue
   ```

4. **Documentation** (`db/docs/CONTRACT_TO_SCHEMA_MAPPING.md:39-58`):
   - Documents conversion: "API: revenue_cents / 100.0"
   - Rationale: "Integer arithmetic is exact, better performance than DECIMAL"

**Conclusion**: **Contracts use `number (float)` in dollars, schema uses `INTEGER` in cents.** Conversion is documented in `db/docs/CONTRACT_TO_SCHEMA_MAPPING.md` and implemented in materialized views (division by 100.0).

---

#### I9.2: Contract-Schema Type Mismatches

**Question**: Are there any known mismatches between contract types and database types that are not yet documented as intentional?

**Answer**: 

**NO UNDOCUMENTED MISMATCHES FOUND**

**Evidence**:
- **Documented Mismatches**:
  - `total_revenue`: Contract `float` → Schema `INTEGER cents` → **DOCUMENTED** in `db/docs/CONTRACT_TO_SCHEMA_MAPPING.md`
  - Conversion logic documented in materialized view comments

- **Type Mappings** (from `db/docs/contract_schema_mapping.yaml:17-23`):
  - `openapi_number_float_currency` → `postgres: integer` with conversion `API: revenue_cents / 100.0` → **DOCUMENTED**

**Conclusion**: **All type mismatches are documented as intentional** with conversion logic specified.

---

#### I9.3: Identifier Mapping

**Question**: Confirm the *intended* mapping: does `attribution_events.external_event_id` correspond to payment processor `transaction_id`?

**Answer**: 

**MAPPING IS NOT EXPLICITLY DOCUMENTED**

**Evidence**:
- **Canonical Schema** (`canonical_schema.sql`): Does NOT define `external_event_id` or `correlation_id` (uses `idempotency_key` only)
- **Initial Migration** (`202511131115_add_core_tables.py:106-107`): Defines `external_event_id text, correlation_id uuid` but **NO documentation of mapping**
- **Migration Comments**: Describe `correlation_id` as "Correlation ID from X-Correlation-ID header" but do NOT map to `transaction_id`

**`revenue_ledger` Identifiers**:
- **Canonical Schema** (`canonical_schema.sql:249`): `transaction_id VARCHAR(255) NOT NULL UNIQUE`
- **Comment** (line 248): "Transaction identity and idempotency (unique per processor)"

**Conclusion**: **No explicit mapping documented.** The relationship between `attribution_events.external_event_id` and `revenue_ledger.transaction_id` is **NOT specified** in schema or migration comments.

---

#### I9.4: Contract Columns Missing from Schema

**Question**: Are there any columns that are defined in contracts but are not present in the B0.3 schema yet?

**Answer**: 

**NO MISSING CONTRACT COLUMNS DETECTED**

**Evidence**:
- **Contract Analysis**: All contract fields (`total_revenue`, `verified`, `data_freshness_seconds`, `tenant_id`) are present in materialized views or base tables
- **Materialized Views**: `mv_realtime_revenue` provides contract-compliant shape (`202511131119_add_materialized_views.py:45-54`)

**Conclusion**: **All contract-required fields are present** (either in base tables or materialized views that transform schema to contract shape).

---

### J. Known Gaps & Explicit Acknowledgements

#### J10.1: Performance Validation Gaps

**Question**: Confirm explicitly that there is **no** stored EXPLAIN/ANALYZE plan, no load-testing scripts, and no matview refresh timing data.

**Answer**: 

**ALL GAPS CONFIRMED**

**Evidence**:
- **EXPLAIN/ANALYZE Plans**: **NONE FOUND** - No stored query plans in repo
- **Load-Testing Scripts**: **NONE FOUND** - No performance testing scripts
- **Matview Refresh Timing**: **NONE FOUND** - No timing data or benchmarks
- **Documentation** (`docs/forensics/archive/implementation-phases/b0.3/B0.3_MV_VALIDATOR_IMPLEMENTATION.md:518-543`): Describes **EXPECTED** query plans but does NOT contain **ACTUAL** EXPLAIN ANALYZE output

**Conclusion**: **All performance validation gaps are CONFIRMED.** No empirical performance data exists in the repository.

---

#### J10.2: ERD Existence

**Question**: `docs/database-schema.md` is referenced in the architecture guide. Confirm whether an actual ERD markdown (or diagram) exists.

**Answer**: 

**ERD EXISTS BUT NOT AT REFERENCED PATH**

**Evidence**:
- **Referenced Path**: `docs/database-schema.md` - **FILE DOES NOT EXIST**
- **Actual ERD**: `db/docs/erd/erd.md` (exists, lines 1-58)
- **ERD Policy**: `db/docs/ERD_POLICY.md` (exists, documents ERD generation process)

**ERD Content** (`db/docs/erd/erd.md`):
- Text-based ERD showing entity relationships
- Documents cardinalities and foreign keys
- **NOT a visual diagram** - text format only

**Conclusion**: **ERD exists at `db/docs/erd/erd.md` but NOT at `docs/database-schema.md`.** The referenced path is **MISSING** relative to the guide.

---

#### J10.3: Operational Runbooks

**Question**: Are there any runbooks or operational docs describing how to troubleshoot RLS issues, retention, or matview staleness?

**Answer**: 

**NO OPERATIONAL RUNBOOKS FOUND**

**Evidence**:
- **RLS Troubleshooting**: **NO runbook found**
- **Retention Troubleshooting**: **NO runbook found**
- **Matview Staleness**: **NO runbook found**
- **Documentation**: Architecture docs describe features but NOT operational troubleshooting procedures

**Conclusion**: **Such runbooks do NOT exist yet.** No operational documentation for troubleshooting database-level issues.

---

## PART B: Engineering Analyst Alex's Questions

### 2.1 JSONB Indexing (B0.4 Blocker)

#### Question 1: GIN Index Omission (attribution_events)

**Question**: Reviewing `alembic/versions/001_core_schema/202511131115_add_core_tables.py`, analysts confirmed no GIN index was implemented on `attribution_events.raw_payload`. Was this omission intentional?

**Answer**: 

**OMISSION IS NOT DOCUMENTED AS INTENTIONAL**

**Evidence**:
- **Migration** (`202511131115_add_core_tables.py:110`): Creates `raw_payload jsonb NOT NULL` but **NO GIN index**
- **No Design Document**: No ADR or design doc justifying GIN index exclusion
- **No Trade-off Documentation**: No write-performance concerns or architectural rationale documented

**Conclusion**: **The omission is UNDOCUMENTED.** There is no evidence of an intentional decision to defer GIN indexing.

---

#### Question 2: GIN Index Omission (dead_events)

**Question**: Analyst Chrisor (Q53) also noted no GIN index on `dead_events.raw_payload`. Can you confirm this is also the case and explain the query strategy for that table?

**Answer**: 

**CONFIRMED - NO GIN INDEX ON `dead_events.raw_payload`**

**Evidence**:
- **Migration** (`202511131115_add_core_tables.py:162`): Creates `raw_payload jsonb NOT NULL` but **NO GIN index**
- **Indexes Created** (`202511131115_add_core_tables.py:170-180`): Only B-tree indexes on `tenant_id`, `source`, `error_code` - **NO JSONB indexes**

**Query Strategy**: **NOT DOCUMENTED**

**Evidence**:
- **Migration Comments**: Do NOT document query patterns for `dead_events`
- **No Query Examples**: No documented queries that filter on `raw_payload` fields

**Conclusion**: **No GIN index exists, and query strategy is NOT documented.** The table appears designed for sequential scans by `tenant_id` and `error_code`, not JSONB field queries.

---

### 2.2 OLAP Index Validation (B0.4 Blocker)

#### Question 3: Query Plan Artifacts

**Question**: Can you access the *most recent `EXPLAIN ANALYZE` output* you generated during development for a query simulating a dashboard request?

**Answer**: 

**NO EXPLAIN ANALYZE OUTPUT FOUND**

**Evidence**:
- **Repository Search**: No `.sql` files containing EXPLAIN ANALYZE output
- **Documentation** (`docs/forensics/archive/implementation-phases/b0.3/B0.3_MV_VALIDATOR_IMPLEMENTATION.md:518-543`): Contains **EXPECTED** query plans (pseudocode) but **NO ACTUAL** EXPLAIN ANALYZE output
- **Test Files**: `db/tests/` contains validation SQL but **NO EXPLAIN ANALYZE plans**

**Conclusion**: **No stored EXPLAIN ANALYZE output exists in the repository.**

---

#### Question 4: Index Implementation for Channel Performance

**Question**: Analyst Samex (Q10) noted the specific index `idx_allocations_channel_performance` (named in the architecture guide) was not found. What is the *actual* `CREATE INDEX` statement you implemented?

**Answer**: 

**INDEX EXISTS IN CANONICAL SCHEMA BUT NOT IN MIGRATIONS**

**Evidence**:
- **Canonical Schema** (`canonical_schema.sql:217-219`): Defines `idx_allocations_channel_performance` on `(tenant_id, channel, created_at DESC) INCLUDE (allocated_revenue_cents, confidence_score)`
- **Migrations**: **NO migration creates this index**
- **Actual Indexes** (`202511131115_add_core_tables.py:214-226`): Creates `idx_attribution_allocations_tenant_created_at` and `idx_attribution_allocations_channel` (separate indexes, not composite)

**Conclusion**: **The canonical index `idx_allocations_channel_performance` is NOT implemented in migrations.** The actual implementation uses **separate indexes** (`tenant_created_at` and `channel`), not the composite index with INCLUDE columns specified in canonical schema.

---

#### Question 5: Validation Process

**Question**: What was the development workflow for validating index performance? Can you point to the `*.sql` test file that contains the benchmark queries?

**Answer**: 

**NO VALIDATION WORKFLOW OR BENCHMARK QUERIES FOUND**

**Evidence**:
- **Test Files** (`db/tests/`): Contains validation SQL for constraints, RLS, foreign keys, but **NO performance benchmark queries**
- **No EXPLAIN ANALYZE Scripts**: No scripts that run EXPLAIN ANALYZE and store results
- **Documentation**: No documented workflow for index performance validation

**Conclusion**: **No validation workflow or benchmark query files exist.** Index performance has NOT been empirically validated.

---

### 2.3 Migration & Audit Integrity (Critical Gaps)

#### Question 6: Migration Rollback Procedure

**Question**: What is the team's documented procedure for testing migration rollbacks? Can you point to the test plan or runbook?

**Answer**: 

**NO DOCUMENTED ROLLBACK TESTING PROCEDURE FOUND**

**Evidence**:
- **CHANGE_CONTROL.md**: Does NOT mention rollback testing
- **Migration Comments**: Some have WARNING comments about data loss but no testing procedure
- **Test Files**: No rollback test scripts or procedures

**Conclusion**: **No documented procedure exists for testing migration rollbacks.** Downgrade functions exist but have NOT been validated via documented test process.

---

#### Question 7: Revenue State Audit Triggers

**Question**: Analysts found no audit triggers on `revenue_ledger` in the core migration. Analyst Samex (Q6) noted a *later* migration (`..._create_revenue_state_transitions.py`). Can you provide the SQL from this *later* migration file?

**Answer**: 

**MIGRATION CREATES TABLE ONLY, NO TRIGGER**

**SQL from Migration** (`202511151450_create_revenue_state_transitions.py:70-88`):

```sql
CREATE TABLE revenue_state_transitions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    ledger_id UUID NOT NULL REFERENCES revenue_ledger(id) ON DELETE CASCADE,
    from_state VARCHAR(50),
    to_state VARCHAR(50) NOT NULL,
    reason TEXT,
    transitioned_at TIMESTAMPTZ NOT NULL DEFAULT now()
)
```

**Trigger Status**: **NO TRIGGER CREATED**

**Evidence**:
- **Migration** (`202511151450_create_revenue_state_transitions.py`): Creates table and index only, **NO CREATE TRIGGER statement**
- **Grep Search**: No trigger functions or triggers for `revenue_state_transitions`

**Conclusion**: **The migration creates the table but does NOT implement a trigger.** State transitions must be written manually by application code.

---

#### Question 8: Audit Data Flow

**Question**: If no database trigger is used, what *application-level* code path is responsible for *manually* writing to the `revenue_state_transitions` table?

**Answer**: 

**NO APPLICATION CODE FOUND**

**Evidence**:
- **Codebase Search**: No code that writes to `revenue_state_transitions`
- **Backend Code**: `backend/app/` does NOT contain revenue ledger update logic
- **No Service Layer**: No B2.4 Matching Service code found

**Conclusion**: **No application-level code path exists for writing to `revenue_state_transitions`.** The audit table is created but has **NO population mechanism** (neither trigger nor application code).

---

### 2.4 Cross-Phase Misalignments (New Failure Points)

#### Question 9: RLS Implementation

**Question**: Can you point to the *exact code* in the backend (e.g., a FastAPI middleware or dependency) that is responsible for calling `set_config` for every authenticated request?

**Answer**: 

**NO APPLICATION CODE FOUND**

**Evidence**:
- **Grep Search** (`grep -r "set_config\|current_setting" backend/`): **ZERO matches**
- **FastAPI Middleware**: No middleware found that sets tenant context
- **Dependencies**: No FastAPI dependencies found that call `set_config`

**Conclusion**: **No application code exists that sets `app.current_tenant_id`.** The RLS policy is defined but **NOT wired to the application layer.** This is a **CRITICAL GAP** - RLS will block all queries until application code is implemented.

**Expected Pattern** (from documentation): FastAPI dependency should call `SET LOCAL app.current_tenant_id = '{tenant_id}'`, but this code does NOT exist.

---

#### Question 10: Materialized View Refresh

**Question**: Can you confirm if a Celery beat task or other scheduler was implemented to call `REFRESH MATERIALIZED VIEW CONCURRENTLY`?

**Answer**: 

**NO CELERY TASK OR SCHEDULER FOUND**

**Evidence**:
- **Codebase Search**: No Celery tasks for materialized view refresh
- **Backend Code**: `backend/app/` does NOT contain Celery task definitions
- **Migration Comments** (`202511131119_add_materialized_views.py:16-19`): States "Refresh policy: CONCURRENTLY with TTL-based refresh (30-60s)" but this is **documentation only, not implementation**

**Conclusion**: **No Celery beat task or scheduler exists.** Materialized view refresh is **NOT implemented** - only documented as a requirement.

---

#### Question 11: Contract vs. Schema Data Type Mismatch

**Question**: The **B0.1 Contract** (`attribution.yaml`) defines `total_revenue` as a **float (dollars)**. The **B0.3 Schema** (`mv_realtime_revenue`) defines the source field as **`revenue_cents` (INTEGER)**. What *application-level code path* is responsible for this cents-to-dollars conversion?

**Answer**: 

**CONVERSION IS IN MATERIALIZED VIEW, NOT APPLICATION CODE**

**Evidence**:

1. **Materialized View** (`202511131119_add_materialized_views.py:49`):
   ```sql
   COALESCE(SUM(rl.revenue_cents), 0) / 100.0 AS total_revenue
   ```
   - Conversion happens **in the database** (division by 100.0)

2. **Application Code**: **NO application code found** that performs conversion
   - **Backend Code**: `backend/app/` does NOT contain revenue conversion logic
   - **API Endpoints**: No endpoint code found that reads from `mv_realtime_revenue`

**Conclusion**: **The conversion is implemented in the materialized view SQL (database layer), NOT in application code.** The matview directly provides `total_revenue` as a float, so application code would read it directly without conversion.

**However**: **No application code exists** that reads from `mv_realtime_revenue`, so the conversion path is **NOT COMPLETE** - the database layer is ready, but the application layer is missing.

---

## SUMMARY OF CRITICAL FINDINGS

### Blocking Issues for B0.4

1. **RLS Not Wired to Application**: No code sets `app.current_tenant_id` - RLS will block all queries
2. **No GIN Indexes on JSONB**: `raw_payload` columns have no indexes - JSONB queries will be slow
3. **No Materialized View Refresh**: Matviews will become stale - no scheduler exists
4. **No Revenue State Audit Triggers**: `revenue_state_transitions` table is empty - no automatic population

### Documentation Gaps

1. **Idempotency Evolution Undocumented**: Move from composite to single-column approach not explained
2. **GIN Index Decision Undocumented**: No rationale for omitting JSONB indexes
3. **Retention Implementation Unspecified**: 90-day deletion requirement not implemented or documented
4. **Performance Validation Missing**: No EXPLAIN ANALYZE plans or benchmarks

### Implementation Completeness

- **Schema Realignment**: ✅ Complete (later migrations align with canonical spec)
- **RLS Policies**: ✅ Defined but ❌ Not wired to application
- **Materialized Views**: ✅ Created but ❌ Not refreshed automatically
- **Audit Tables**: ✅ Created but ❌ Not populated automatically

---

**END OF FORENSIC ANALYSIS**




