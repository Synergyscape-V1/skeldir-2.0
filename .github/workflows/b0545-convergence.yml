name: b0545-convergence

on:
  pull_request:
    paths:
      - ".github/workflows/b0545-convergence.yml"
      - "backend/**"
      - "alembic/**"
      - "scripts/**"
  workflow_dispatch:

jobs:
  b0545-convergence:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      DATABASE_URL: postgresql://app_user:app_user@127.0.0.1:5432/skeldir_validation
      MIGRATION_DATABASE_URL: postgresql://app_user:app_user@127.0.0.1:5432/skeldir_validation
      CELERY_BROKER_URL: sqla+postgresql://app_user:app_user@127.0.0.1:5432/skeldir_validation
      CELERY_RESULT_BACKEND: db+postgresql://app_user:app_user@127.0.0.1:5432/skeldir_validation
      CELERY_METRICS_PORT: "9546"
      CELERY_METRICS_ADDR: "127.0.0.1"
      ZG_BEAT_TEST_INTERVAL_SECONDS: "5"
      PYTHONPATH: backend
      CI: "true"
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Remove repo .env for CI isolation
        run: rm -f .env

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt -r backend/requirements-dev.txt

      - name: Install psql client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Prepare database and roles
        run: |
          set -euo pipefail
          echo "Creating database roles and skeldir_validation database..."
          PGPASSWORD=postgres psql -h localhost -U postgres -c "CREATE USER app_user WITH PASSWORD 'app_user';"
          PGPASSWORD=postgres psql -h localhost -U postgres -c "CREATE USER app_rw WITH PASSWORD 'app_rw';"
          PGPASSWORD=postgres psql -h localhost -U postgres -c "CREATE USER app_ro WITH PASSWORD 'app_ro';"
          PGPASSWORD=postgres psql -h localhost -U postgres -c "CREATE DATABASE skeldir_validation OWNER app_user;"
          PGPASSWORD=postgres psql -h localhost -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE skeldir_validation TO app_user;"
          PGPASSWORD=postgres psql -h localhost -U postgres -d skeldir_validation -c "GRANT ALL ON SCHEMA public TO app_user;"
          PGPASSWORD=postgres psql -h localhost -U postgres -d skeldir_validation -c "GRANT ALL ON SCHEMA public TO app_rw;"
          PGPASSWORD=postgres psql -h localhost -U postgres -d skeldir_validation -c "GRANT USAGE ON SCHEMA public TO app_ro;"
          echo "Database setup complete"

      - name: Run migrations
        run: |
          set -euo pipefail
          alembic upgrade 202511131121
          alembic upgrade skeldir_foundation@head

      - name: Seed tenant for matview pulse
        run: |
          set -euo pipefail
          psql "${DATABASE_URL}" -c "INSERT INTO tenants (id, name, api_key_hash, notification_email) VALUES ('11111111-1111-1111-1111-111111111111', 'B0545 Tenant', 'B0545_11111111-1111-1111-1111-111111111111', 'b0545-tenant@example.com') ON CONFLICT (id) DO NOTHING;"

      - name: Start worker + beat and capture kinetic evidence
        run: |
          set -euo pipefail
          EVIDENCE_DIR="${GITHUB_WORKSPACE}/evidence/b0545_ci"
          mkdir -p "${EVIDENCE_DIR}"
          printf "sha=%s\nworkflow=%s\n" "${GITHUB_SHA}" "${GITHUB_WORKFLOW}" > "${EVIDENCE_DIR}/metadata.txt"
          printf "database_url=%s\ncelery_broker_url=%s\ncelery_result_backend=%s\n" \
            "${DATABASE_URL}" "${CELERY_BROKER_URL}" "${CELERY_RESULT_BACKEND}" \
            | sed 's/:[^@]*@/:***@/' >> "${EVIDENCE_DIR}/metadata.txt"

          export PYTHONPATH="${GITHUB_WORKSPACE}/backend:${PYTHONPATH}"

          psql "${DATABASE_URL}" -c "select count(*) from worker_failed_jobs;" > "${EVIDENCE_DIR}/worker_failed_jobs_before.txt"
          psql "${DATABASE_URL}" -c "select count(*) from kombu_message;" > "${EVIDENCE_DIR}/kombu_message_before.txt"

          stdbuf -oL -eL celery -A app.celery_app.celery_app worker -P solo -c 1 --loglevel=INFO \
            > "${EVIDENCE_DIR}/worker.log" 2>&1 &
          echo $! > "${EVIDENCE_DIR}/worker.pid"

          for i in $(seq 1 20); do
            celery -A app.celery_app.celery_app inspect ping > "${EVIDENCE_DIR}/inspect_ping.txt" 2>&1 || true
            if grep -q "pong" "${EVIDENCE_DIR}/inspect_ping.txt"; then
              break
            fi
            sleep 2
          done
          cat "${EVIDENCE_DIR}/inspect_ping.txt" || true

          stdbuf -oL -eL celery -A app.celery_app.celery_app beat --loglevel=INFO \
            > "${EVIDENCE_DIR}/beat.log" 2>&1 &
          echo $! > "${EVIDENCE_DIR}/beat.pid"

          for i in $(seq 1 30); do
            if grep -q "Sending due task" "${EVIDENCE_DIR}/beat.log"; then
              break
            fi
            sleep 2
          done
          grep -n "Sending due task" "${EVIDENCE_DIR}/beat.log" | tail -n 5 > "${EVIDENCE_DIR}/beat_due_task.txt" || true
          grep -n "pulse_matviews_global" "${EVIDENCE_DIR}/beat.log" | tail -n 10 > "${EVIDENCE_DIR}/beat_pulse_task.txt" || true

          for i in $(seq 1 30); do
            if grep -q "matview_pulse_task_start" "${EVIDENCE_DIR}/worker.log"; then
              break
            fi
            sleep 2
          done
          grep -n "received task" "${EVIDENCE_DIR}/worker.log" | tail -n 10 > "${EVIDENCE_DIR}/worker_received.txt" || true
          grep -n "matview_pulse_task_start" "${EVIDENCE_DIR}/worker.log" | tail -n 5 > "${EVIDENCE_DIR}/worker_pulse_start.txt" || true
          grep -n "matview_pulse_task_dispatched" "${EVIDENCE_DIR}/worker.log" | tail -n 5 > "${EVIDENCE_DIR}/worker_pulse_dispatched.txt" || true

          CORRELATION_ID="22222222-2222-2222-2222-222222222222"
          KWARGS=$(python - <<'PY'
          import json
          print(json.dumps({
              "tenant_id": "11111111-1111-1111-1111-111111111111",
              "view_name": "mv_nonexistent",
              "correlation_id": "22222222-2222-2222-2222-222222222222",
              "schedule_class": "minute",
          }))
          PY
          )
          celery -A app.celery_app.celery_app call app.tasks.matviews.refresh_single \
            --kwargs "${KWARGS}" > "${EVIDENCE_DIR}/force_failure_call.txt" 2>&1 || true

          sleep 5
          psql "${DATABASE_URL}" -c "select count(*) from worker_failed_jobs;" > "${EVIDENCE_DIR}/worker_failed_jobs_after.txt"
          psql "${DATABASE_URL}" -c "select task_name, correlation_id, error_type, error_message from worker_failed_jobs where correlation_id='${CORRELATION_ID}' order by failed_at desc limit 5;" > "${EVIDENCE_DIR}/worker_failed_jobs_row.txt"
          psql "${DATABASE_URL}" -c "select count(*) from kombu_message;" > "${EVIDENCE_DIR}/kombu_message_after.txt"

          if [ -f "${EVIDENCE_DIR}/beat.pid" ]; then
            kill "$(cat "${EVIDENCE_DIR}/beat.pid")" || true
          fi
          if [ -f "${EVIDENCE_DIR}/worker.pid" ]; then
            kill "$(cat "${EVIDENCE_DIR}/worker.pid")" || true
          fi

      - name: Assert evidence non-empty
        run: |
          set -euo pipefail
          EVIDENCE_DIR="${GITHUB_WORKSPACE}/evidence/b0545_ci"
          required=(
            "beat.log"
            "worker.log"
            "inspect_ping.txt"
            "beat_due_task.txt"
            "worker_received.txt"
            "worker_failed_jobs_after.txt"
            "worker_failed_jobs_row.txt"
          )
          for name in "${required[@]}"; do
            path="${EVIDENCE_DIR}/${name}"
            if [ ! -s "${path}" ]; then
              echo "Missing or empty evidence file: ${path}"
              exit 1
            fi
          done

      - name: Upload B0545 kinetic evidence artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: b0545-kinetic-evidence-${{ github.sha }}
          path: evidence/b0545_ci/
          retention-days: 30
